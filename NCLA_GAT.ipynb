{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import random\n",
    "from utils import *\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 heads,\n",
    "                 attn_drop,\n",
    "                 negative_slope):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        # self.gat_layers = nn.ModuleList()\n",
    "        self.gat1 = GATConv(in_dim, num_hidden, heads, dropout= attn_drop, add_self_loops  = False, negative_slope = negative_slope)\n",
    "        # self.gat_layers.append(GATConv(in_dim, num_hidden, heads, dropout= attn_drop, add_self_loops  = False, negative_slope = negative_slope))\n",
    "        # hidden layers\n",
    "        # for l in range(1, num_layers):\n",
    "        #     # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "        #     self.gat_layers.append(GATConv(in_dim, num_hidden, heads, dropout= attn_drop, add_self_loops  = False, negative_slope = negative_slope))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        heads = []\n",
    "        h = inputs\n",
    "        # get hidden_representation\n",
    "        for l in range(self.num_layers):\n",
    "            h =self.gat_layers[l](self.g, h)\n",
    "        # get heads\n",
    "        for i in range(h.shape[1]):\n",
    "            heads.append(h[:, i])\n",
    "        return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.randn(50, 5)\n",
    "graph_data = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50.pkl\")\n",
    "g = graph_data[0]\n",
    "x = torch.eye(g.number_of_nodes())  # 节点特征\n",
    "edge_index = torch.tensor(list(g.edges)).t().contiguous()\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "model = GAT(data,num_layers = 1, in_dim = 5, num_hidden = 32, heads = 4, attn_drop = 0.5, negative_slope = 0.2)\n",
    "model.train()\n",
    "output = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnModify(nn.Module):\n",
    "    def __init__(self, num_features, graph_embedding_size, epoch = 100, lr = 0.0001, modified_edge = 100, GraphNumber = 50, Graphsize = 50, num_heads = 4):\n",
    "        super(LearnModify, self).__init__()\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "        self.modified_edge = modified_edge\n",
    "        self.GraphNumber = GraphNumber\n",
    "        self.Graphsize = Graphsize\n",
    "        self.GAT_num_hidden = 32\n",
    "        self.GAT_num_layers = 1\n",
    "        self.GAT_num_features = num_features\n",
    "        self.GAT_attn_drop = 0.5\n",
    "        self.negative_slope = 0.2\n",
    "        self.num_heads = num_heads\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_layers = 1\n",
    "num_feats = 50\n",
    "num_hidden = 32\n",
    "in_drop = 0.6\n",
    "attn_drop = 0.5\n",
    "negative_slope = 0.2\n",
    "heads = 4\n",
    "graph_data = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50.pkl\")\n",
    "g = graph_data[0]\n",
    "model = GAT(g,\n",
    "            num_layers,\n",
    "            num_feats,\n",
    "            num_hidden,\n",
    "            heads,\n",
    "            F.elu,\n",
    "            in_drop,\n",
    "            attn_drop,\n",
    "            negative_slope)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
