{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import random\n",
    "from heapdict import heapdict\n",
    "from node2vec import Node2Vec\n",
    "import argparse\n",
    "import torch.nn.init as init\n",
    "from utils import *\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义GCN模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_features, graph_embedding_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 128)\n",
    "        self.conv2 = GCNConv(128, graph_embedding_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定义GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_heads=4, graph_embedding_size=256):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(num_features, 512, heads=num_heads, dropout=0.2)\n",
    "        self.gat2 = GATConv(512 * num_heads, graph_embedding_size, heads=1, concat=False, dropout=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定義用來決定edge是否修改的MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc5.weight, nonlinearity='relu')\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pro = torch.softmax(self.fc4(x), dim=1)\n",
    "        binary_decision = torch.sigmoid(self.fc5(x))\n",
    "        return pro, binary_decision\n",
    "    \n",
    "class GCN_edge_modify(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels = 512):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # 最后一层，用于产生最终输出\n",
    "        self.out = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "class MLPClassifier(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 256)          # 第二层\n",
    "        self.fc3 = nn.Linear(256, 128)          # 第三层\n",
    "        self.fc4 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))        # 使用sigmoid确保输出在0到1之间\n",
    "        return x\n",
    "    \n",
    "class MVC_Predict(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 256)          # 第二层\n",
    "        self.fc3 = nn.Linear(256, 128)          # 第三层\n",
    "        self.fc4 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)       # 使用sigmoid确保输出在0到1之间\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modify_edge(nn.Module):\n",
    "    def __init__(self, num_features, graph_embedding_size, epoch = 100, lr = 0.0001, modified_edge = 30, GraphNumber = 50, Graphsize = 50, num_heads = 4):\n",
    "        super(Modify_edge, self).__init__()\n",
    "        self.connect_info_num = 5\n",
    "        self.gat = GAT(num_features=num_features + 1, num_heads=num_heads, graph_embedding_size = graph_embedding_size)  # 根据需要调整头数\n",
    "        self.mlp = MLP(input_size=3 * graph_embedding_size + self.connect_info_num)\n",
    "        self.classifier = MLPClassifier(input_size=2 * graph_embedding_size)\n",
    "        self.modified_edge = modified_edge\n",
    "        self.lr = lr\n",
    "        self.GraphNumber = GraphNumber\n",
    "        self.Graphsize = Graphsize\n",
    "        self.Node2Vec_feature = num_features\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.best_preserve = 0\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        self.modified_graphs = []\n",
    "        self.edge_dict = {}\n",
    "        self.whole_edge_set = set()\n",
    "        self.dataset = []\n",
    "        self.init_graph()  ## create self.dataset\n",
    "        \n",
    "        original_embeddings = []\n",
    "        for data in self.dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            original_embeddings.append(embedding)\n",
    "        self.original_graph_embeddings = self.get_graph_embedding(original_embeddings)\n",
    "        self.mlp_label = []\n",
    "        self.mlp_target = []\n",
    "        for emb, data, graph_emb in zip(original_embeddings, self.dataset, self.original_graph_embeddings):\n",
    "            modify_edge, edge_label, edge_softmax = self.generate_edge_embeddings(data, emb, graph_emb)\n",
    "            self.mlp_label.append(edge_label)\n",
    "            self.mlp_target.append(edge_softmax)\n",
    "            # print(f\"mlp_label grad : {edge_label.requires_grad}, mlp_target grad : {edge_softmax.requires_grad}\")\n",
    "            add_num = 0\n",
    "            delete_num = 0\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            G_edge_set = set(G.edges())\n",
    "            for edge in modify_edge:  # decision: (probabilities,(u,v))\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    delete_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    add_num += 1\n",
    "            self.modified_graphs.append(G)\n",
    "        \n",
    "        self.modified_dataset = []  #type pyg\n",
    "        for G in self.modified_graphs:\n",
    "            # 从 NetworkX 图创建边索引\n",
    "            edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            # 使用单位矩阵作为节点特征\n",
    "            # x = torch.eye(G.number_of_nodes())\n",
    "            \n",
    "            # 创建 Data 对象\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.modified_dataset.append(data)  \n",
    "            \n",
    "        modified_embeddings = []\n",
    "        for data in self.modified_dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            modified_embeddings.append(embedding)  \n",
    "        self.modified_graph_embeddings = self.get_graph_embedding(modified_embeddings)\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        self.cosine_similarities = cos(self.modified_graph_embeddings, self.original_graph_embeddings).mean()\n",
    "            \n",
    "        labels = []\n",
    "        MVC_diff = 0\n",
    "        for mod_graph, orig_mvc in zip(self.modified_graphs, self.train_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(mod_graph))\n",
    "            print(f\"mod_mvc: {mod_mvc}, ori_mvc: {orig_mvc}, diff: {abs(mod_mvc - orig_mvc)}\")\n",
    "            MVC_diff = MVC_diff + abs(mod_mvc - orig_mvc) * abs(mod_mvc - orig_mvc)\n",
    "            label = 1 if mod_mvc == orig_mvc else 0\n",
    "            labels.append(label)\n",
    "        print(f\"label presreved: {labels.count(1)}, MVC_diff : {MVC_diff}\")\n",
    "        label_preserve = labels.count(1)\n",
    "        if label_preserve > self.best_preserve:\n",
    "            self.best_preserve = label_preserve\n",
    "            torch.save(self.state_dict(), \"/workspace/Model/Modify_edge_model_1.pth\")\n",
    "        combined_embeddings = [torch.cat((mod_emb, orig_emb)) for mod_emb, orig_emb in zip(self.modified_graph_embeddings, self.original_graph_embeddings)]\n",
    "        # 将嵌入和标签转换为张量\n",
    "        combined_embeddings_tensor = torch.stack(combined_embeddings)\n",
    "        # combined_embeddings_tensor shape : torch.Size([50, 2*graph embedding]) 兩張graph的嵌入拼接起來\n",
    "        self.labels_tensor = torch.tensor(labels).to(self.device)\n",
    "        # labels_tensor shape : torch.Size([50]) 也就是50個graph的label\n",
    "        self.preserve_predict = self.classifier(combined_embeddings_tensor).squeeze()\n",
    "        # preserve_predict shape: torch.Size([50])也就是50個graph預測的label\n",
    "        \n",
    "        self.mlp_label = torch.stack(self.mlp_label, dim=0) # shape: torch.Size([50, 1225])\n",
    "        self.mlp_target = torch.stack(self.mlp_target, dim=0) # shape: torch.Size([50, 1225])\n",
    "\n",
    "        \n",
    "        return self.cosine_similarities, self.preserve_predict, self.labels_tensor, MVC_diff/self.GraphNumber, label_preserve, self.mlp_label, self.mlp_target\n",
    "        \n",
    "        \n",
    "    def init_graph(self):\n",
    "        \"\"\"construct or load training graph and use Node2vec to get node embedding\"\"\"\n",
    "        self.train_graphs, self.train_opt = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50_withOPT.pkl\")\n",
    "        self.create_edge_dict(self.Graphsize)\n",
    "        for i in range(self.GraphNumber):\n",
    "            # p = random.uniform(graph_density[0], graph_density[1])\n",
    "            # G = nx.erdos_renyi_graph(graph_size, p)\n",
    "            G = self.train_graphs[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "            # x = torch.eye(G.number_of_nodes())  # 节点特征\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.dataset.append(data)\n",
    "            \n",
    "    def create_edge_dict(self,graph_size):\n",
    "        \"\"\"mapping edge to index\"\"\"\n",
    "        index = 0\n",
    "        for i in range(graph_size - 1):\n",
    "            for j in range(i + 1, graph_size):\n",
    "                self.whole_edge_set.add((i, j))\n",
    "                self.edge_dict[(i, j)] = index\n",
    "                index += 1\n",
    "        \n",
    "    def calculate_MVC(self,graph, UB=9999999, C=set()):\n",
    "        \"\"\"use branch and bound to find out the mvc result\"\"\"\n",
    "        if len(graph.edges()) == 0:\n",
    "            return C\n",
    "\n",
    "        v, _ = max(graph.degree(), key=lambda a: a[1])\n",
    "        # C1 分支：選擇鄰居\n",
    "        C1 = C.copy()\n",
    "        neighbors = set(graph.neighbors(v))\n",
    "        C1.update(neighbors)\n",
    "        graph_1 = graph.copy()\n",
    "        graph_1.remove_nodes_from(neighbors)\n",
    "        if len(C1) < UB:\n",
    "            C1 = self.calculate_MVC(graph_1, UB, C1)\n",
    "\n",
    "        # C2 分支：只選擇該節點\n",
    "        C2 = C.copy()\n",
    "        C2.add(v)\n",
    "        graph_2 = graph.copy()\n",
    "        graph_2.remove_node(v)\n",
    "        if len(C2) < UB:\n",
    "            C2 = self.calculate_MVC(graph_2, min(UB, len(C1)), C2)\n",
    "\n",
    "        return min(C1, C2, key=len)\n",
    "    \n",
    "    def predict_MVC (self,graph_emb):\n",
    "        \"\"\"predict the result of MVC\"\"\"\n",
    "        for emb in graph_emb:\n",
    "            result = self.MVC_predict(emb)\n",
    "            print(result)\n",
    "    \n",
    "    def get_graph_embedding(self,embeddings):\n",
    "        \"\"\"average all node embeddings to get graph embedding, embedding 是一個list，每個元素是一個graph的node embedding\"\"\"\n",
    "        graph_embeddings = []\n",
    "        for embedding in embeddings:\n",
    "            graph_embedding = embedding.mean(dim=0)  # 对所有节点嵌入求平均\n",
    "            graph_embeddings.append(graph_embedding)\n",
    "        return torch.stack(graph_embeddings)\n",
    "    \n",
    "    def generate_edge_embeddings(self,data, embedding, graph_emb):\n",
    "        \"\"\"generate and sample edge embeddings for training 需要修改\"\"\"\n",
    "        data= to_networkx(data, to_undirected=True)\n",
    "        edge_set = set(data.edges()) \n",
    "        edge_modify_label = [torch.tensor(0.0) for _ in range(len(self.whole_edge_set))]\n",
    "        edge_modify_softmax = []\n",
    "        edge_pro_list = []\n",
    "        none_edge_pro_list = []\n",
    "        gumbel_modify_edge = []  #紀錄那些邊被修改\n",
    "        for u,v in self.whole_edge_set:\n",
    "            node1_emb = embedding[u]\n",
    "            node2_emb = embedding[v]\n",
    "            if (u,v) in edge_set:\n",
    "                connect_info = torch.tensor([1.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb,connect_info , graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                gumbel_modify_edge.append((u,v))\n",
    "\n",
    "            else:\n",
    "                connect_info = torch.tensor([0.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb, connect_info, graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                none_edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                gumbel_modify_edge.append((u,v))\n",
    "        \n",
    "        \"\"\"計算label不需用gradient\"\"\"\n",
    "        edge_pro_list = sorted(edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        none_edge_pro_list = sorted(none_edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        for i in range(len(edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0)\n",
    "        for i in range(len(none_edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[none_edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0)\n",
    "        # print(f\"len of edge_modify_label : {len of edge_modify_softmax : {len(edge_modify_softmax)}, len(edge_modify_label)}, type of edge_modify_softmax[0] : {type(edge_modify_softmax[0])}, type of edge_modify_label[0] : {type(edge_modify_label[0])}\")\n",
    "        # print(f\"true in edge_modify_softmax : {edge_modify_softmax.count(torch.tensor(1.0))}, true in edge_modify_label : {edge_modify_label.count(torch.tensor(1.0))}, edge_modify_label : { edge_modify_label}\")\n",
    "        \n",
    "        combined_embeddings = gumbel_modify_edge\n",
    "        edge_modify_label = torch.stack(edge_modify_label, dim=0)\n",
    "        edge_modify_softmax = torch.stack(edge_modify_softmax, dim=0)\n",
    "        \n",
    "        return combined_embeddings, edge_modify_label, edge_modify_softmax\n",
    "    \n",
    "    def validation(self):\n",
    "        validation_data, valid_opt, pro = pickle_load(\"/workspace/Synthetic_graph/Validation_graph_200_withOPTPRO.pkl\")\n",
    "        valid_original_embeddings = []\n",
    "        self.valid_dataset = []\n",
    "        self.valid_modified_graphs = []\n",
    "        # 把validation data轉成pyg的data，並透過node2vec得到node feature，再輸入GAT得到node embedding，最後透過get_graph_embedding得到graph embedding\n",
    "        for i in range(len(validation_data)):\n",
    "            G = validation_data[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.valid_dataset.append(data)\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            valid_original_embeddings.append(embedding)\n",
    "        self.valid_graph_embedding = self.get_graph_embedding(valid_original_embeddings)\n",
    "        \n",
    "        # 將每個graph的node embedding和graph embedding還有pyg data輸入generate_edge_embeddings得到要修改的edge，並直接修改成新的graph，用valid_modified_graphs儲存\n",
    "        for emb, data, graph_emb in zip(valid_original_embeddings, self.valid_dataset, self.valid_graph_embedding):\n",
    "            modify_edge = self.generate_edge_embeddings(data, emb, graph_emb) #pyg data是為了知道邊\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            for decision in modify_edge:\n",
    "                edge = decision[1]\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "            self.valid_modified_graphs.append(G)\n",
    "        \n",
    "        valid_label_presever = 0\n",
    "        for val_mod_graph, ori_opt in zip(self.valid_modified_graphs, valid_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(val_mod_graph))\n",
    "            if ori_opt == mod_mvc:\n",
    "                valid_label_presever += 1\n",
    "        print(f\"validation label presreved: {valid_label_presever}\")\n",
    "        \n",
    "    def return_graph_embedding(self,G):\n",
    "        \"\"\"average all node embeddings to get graph embedding\"\"\"\n",
    "        adj_matrix = nx.adjacency_matrix(G)\n",
    "        adj_matrix = coo_matrix(adj_matrix)\n",
    "        row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "        col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "        InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "        # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "        node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "        node2vec_features_np = np.array(node2vec_embeddings)\n",
    "        degrees = nx.degree(G)\n",
    "        degree_values = [deg for node, deg in degrees]\n",
    "        degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "        degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "        degree_features = degree_normalized.view(-1, 1)\n",
    "        node2vec_features = torch.tensor(node2vec_features_np)\n",
    "        combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "        data = Data(x=combined_features, edge_index=edge_index)\n",
    "        embedding = self.gat(data)\n",
    "        graph_embedding = self.get_graph_embedding([embedding])\n",
    "        return graph_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel\n",
      "gat.gat1.att_src: requires_grad=True\n",
      "gat.gat1.att_dst: requires_grad=True\n",
      "gat.gat1.bias: requires_grad=True\n",
      "gat.gat1.lin_src.weight: requires_grad=True\n",
      "gat.gat2.att_src: requires_grad=True\n",
      "gat.gat2.att_dst: requires_grad=True\n",
      "gat.gat2.bias: requires_grad=True\n",
      "gat.gat2.lin_src.weight: requires_grad=True\n",
      "mlp.fc1.weight: requires_grad=True\n",
      "mlp.fc1.bias: requires_grad=True\n",
      "mlp.fc2.weight: requires_grad=True\n",
      "mlp.fc2.bias: requires_grad=True\n",
      "mlp.fc3.weight: requires_grad=True\n",
      "mlp.fc3.bias: requires_grad=True\n",
      "mlp.fc4.weight: requires_grad=True\n",
      "mlp.fc4.bias: requires_grad=True\n",
      "mlp.fc5.weight: requires_grad=True\n",
      "mlp.fc5.bias: requires_grad=True\n",
      "classifier.fc1.weight: requires_grad=True\n",
      "classifier.fc1.bias: requires_grad=True\n",
      "classifier.fc2.weight: requires_grad=True\n",
      "classifier.fc2.bias: requires_grad=True\n",
      "classifier.fc3.weight: requires_grad=True\n",
      "classifier.fc3.bias: requires_grad=True\n",
      "classifier.fc4.weight: requires_grad=True\n",
      "classifier.fc4.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_sample_number = 50\n",
    "learning_rate = 0.0001\n",
    "mymodel = Modify_edge(num_features=128, graph_embedding_size=256, epoch=100, lr=learning_rate, modified_edge=edge_sample_number, GraphNumber=50, Graphsize=50, num_heads=4)\n",
    "# mymodel.load_state_dict(torch.load(\"/workspace/backup/Modify_edge_model_1.pth\"))\n",
    "mymodel = mymodel.to(device)\n",
    "print(\"mymodel\")\n",
    "for name, param in mymodel.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "BCEloss_fn = nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=learning_rate,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 0, Loss: 26.019454956054688, similarity_loss: 0.9189621806144714, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6899634003639221, mlp_loss : 50.30530548095703\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 1, Loss: 25.661916732788086, similarity_loss: 0.9213311672210693, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6768300533294678, mlp_loss : 46.83755111694336\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 2, Loss: 25.371082305908203, similarity_loss: 0.9316356182098389, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6640197038650513, mlp_loss : 43.95428466796875\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 3, Loss: 25.13304328918457, similarity_loss: 0.9436885714530945, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6480499505996704, mlp_loss : 41.613059997558594\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 4, Loss: 24.877254486083984, similarity_loss: 0.9469106197357178, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6287127137184143, mlp_loss : 39.21632766723633\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 45, ori_mvc: 38, diff: 7\n",
      "mod_mvc: 37, ori_mvc: 45, diff: 8\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 42, diff: 0\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 43, ori_mvc: 41, diff: 2\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 39, ori_mvc: 44, diff: 5\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 40, diff: 5\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 38, ori_mvc: 45, diff: 7\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 43, ori_mvc: 42, diff: 1\n",
      "mod_mvc: 40, ori_mvc: 44, diff: 4\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 45, ori_mvc: 39, diff: 6\n",
      "mod_mvc: 40, ori_mvc: 45, diff: 5\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 41, ori_mvc: 44, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 41, ori_mvc: 43, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 44, diff: 2\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 42, ori_mvc: 43, diff: 1\n",
      "mod_mvc: 45, ori_mvc: 37, diff: 8\n",
      "mod_mvc: 44, ori_mvc: 40, diff: 4\n",
      "mod_mvc: 44, ori_mvc: 41, diff: 3\n",
      "mod_mvc: 44, ori_mvc: 39, diff: 5\n",
      "label presreved: 1, MVC_diff : 920\n",
      "Epoch: 5, Loss: 24.726760864257812, similarity_loss: 0.9586215019226074, difference_loss: 18.4, none_label_preserve: 0.98, classifier_loss: 0.6016902327537537, mlp_loss : 37.8644905090332\n"
     ]
    }
   ],
   "source": [
    "diff_weight = 1 # MVC修改前後的差異\n",
    "similarity_weight = 1 # 修改前後的圖的相似度\n",
    "preserve_weight = 1 # 保留原本的label\n",
    "classification_weight = 1 # 用來判定graph的result是否有相同的MVC\n",
    "mlp_loss_weight = 0.1\n",
    "for epoch in range(100):\n",
    "    mymodel.train()\n",
    "    similarity_loss , preserve_predict, labels_tensor, difference_loss, label_preserve, mlp_label, mlp_target = mymodel()\n",
    "        \n",
    "    mlp_loss = BCEloss_fn(mlp_target, mlp_label)   \n",
    "    \n",
    "    classifier_loss = criterion(preserve_predict, labels_tensor.float())\n",
    "    \n",
    "    none_preserve_loss = (mymodel.GraphNumber-label_preserve) /  mymodel.GraphNumber\n",
    "    \n",
    "    loss = classifier_loss * classification_weight + similarity_loss * similarity_weight + difference_loss * diff_weight + none_preserve_loss * preserve_weight + mlp_loss * mlp_loss_weight\n",
    "    \n",
    "    # loss = similarity_loss * similarity_weight + difference_loss * diff_weight + none_preserve * preserve_weight\n",
    "      \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # for name, param in mymodel.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"Gradient of {name}: {param.grad.norm()}\")\n",
    "    #     else:\n",
    "    #         print(f\"Gradient of {name}: None\")\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, similarity_loss: {similarity_loss.item()}, difference_loss: {difference_loss}, none_label_preserve: {none_preserve_loss}, classifier_loss: {classifier_loss.item()}, mlp_loss : {mlp_loss.item()}\")\n",
    "    # if epoch % 2 == 0:\n",
    "    #     print(\"validation\")\n",
    "    #     mymodel.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         mymodel.validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
