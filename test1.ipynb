{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import random\n",
    "from heapdict import heapdict\n",
    "from node2vec import Node2Vec\n",
    "import argparse\n",
    "import torch.nn.init as init\n",
    "from utils import *\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_heads=4, graph_embedding_size=256, hidden_dim=1024,  dropout=0.2):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(num_features, hidden_dim, heads=num_heads, dropout=dropout, add_self_loops = False)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, graph_embedding_size, heads=1, concat=False, dropout=dropout, add_self_loops = False)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定義用來決定edge是否修改的MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc5.weight, nonlinearity='relu')\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pro = torch.softmax(self.fc4(x), dim=1)\n",
    "        binary_decision = torch.sigmoid(self.fc5(x))\n",
    "        return pro, binary_decision\n",
    "    \n",
    "class MLPClassifier(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 256)          # 第二层\n",
    "        self.fc3 = nn.Linear(256, 128)          # 第三层\n",
    "        self.fc4 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))        # 使用sigmoid确保输出在0到1之间\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modify_edge(nn.Module):\n",
    "    def __init__(self, num_features, graph_embedding_size, epoch = 100, lr = 0.0001, modified_edge = 30, GraphNumber = 50, Graphsize = 50, num_heads = 4):\n",
    "        super(Modify_edge, self).__init__()\n",
    "        self.connect_info_num = 5\n",
    "        self.gat = GAT(num_features=num_features + 1, num_heads=num_heads, graph_embedding_size = graph_embedding_size)  # 根据需要调整头数\n",
    "        self.mlp = MLP(input_size=3 * graph_embedding_size + self.connect_info_num)\n",
    "        self.classifier = MLPClassifier(input_size=2 * graph_embedding_size)\n",
    "        self.modified_edge = modified_edge\n",
    "        self.lr = lr\n",
    "        self.GraphNumber = GraphNumber\n",
    "        self.Graphsize = Graphsize\n",
    "        self.Node2Vec_feature = num_features\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.best_preserve = 0\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        self.modified_graphs = []\n",
    "        self.edge_dict = {}\n",
    "        self.whole_edge_set = set()\n",
    "        self.dataset = []\n",
    "        self.init_graph()  ## create self.dataset\n",
    "        \n",
    "        original_embeddings = []\n",
    "        for data in self.dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            original_embeddings.append(embedding)\n",
    "        self.original_graph_embeddings = self.get_graph_embedding(original_embeddings)\n",
    "        self.mlp_label = []\n",
    "        self.mlp_target = []\n",
    "        for emb, data, graph_emb in zip(original_embeddings, self.dataset, self.original_graph_embeddings):\n",
    "            modify_edge, edge_label, edge_softmax = self.generate_edge_embeddings(data, emb, graph_emb)\n",
    "            self.mlp_label.append(edge_label)\n",
    "            self.mlp_target.append(edge_softmax)\n",
    "            add_num = 0\n",
    "            delete_num = 0\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            for edge in modify_edge:  # decision: (probabilities,(u,v))\n",
    "                if edge[0] == edge[1]:\n",
    "                    print(\"self loop\")\n",
    "                    continue\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    delete_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    add_num += 1\n",
    "            self.modified_graphs.append(G)\n",
    "            print(f\"add_num: {add_num}, delete_num: {delete_num}\")\n",
    "        self.modified_dataset = []  #type pyg\n",
    "        for G in self.modified_graphs:\n",
    "            # 从 NetworkX 图创建边索引\n",
    "            edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            # 使用单位矩阵作为节点特征\n",
    "            # x = torch.eye(G.number_of_nodes())\n",
    "            \n",
    "            # 创建 Data 对象\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.modified_dataset.append(data)  \n",
    "            \n",
    "        modified_embeddings = []\n",
    "        for data in self.modified_dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            modified_embeddings.append(embedding)  \n",
    "        self.modified_graph_embeddings = self.get_graph_embedding(modified_embeddings)\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        self.cosine_similarities = cos(self.modified_graph_embeddings, self.original_graph_embeddings).mean()\n",
    "        \n",
    "        self.calculate_adj_similarity(self.train_graphs, self.modified_graphs)\n",
    "        \n",
    "        labels = []\n",
    "        MVC_diff = 0\n",
    "        for mod_graph, orig_mvc in zip(self.modified_graphs, self.train_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(mod_graph))\n",
    "            # print(f\"mod_mvc: {mod_mvc}, ori_mvc: {orig_mvc}, diff: {abs(mod_mvc - orig_mvc)}\")\n",
    "            MVC_diff = MVC_diff + abs(mod_mvc - orig_mvc) * abs(mod_mvc - orig_mvc)\n",
    "            label = 1 if mod_mvc == orig_mvc else 0\n",
    "            labels.append(label)\n",
    "        print(f\"label presreved: {labels.count(1)}, MVC_diff : {MVC_diff}\")\n",
    "        label_preserve = labels.count(1)\n",
    "        if label_preserve > self.best_preserve:\n",
    "            self.best_preserve = label_preserve\n",
    "            torch.save(self.state_dict(), \"/workspace/Model/Modify_edge_model_1.pth\")\n",
    "        combined_embeddings = [torch.cat((mod_emb, orig_emb)) for mod_emb, orig_emb in zip(self.modified_graph_embeddings, self.original_graph_embeddings)]\n",
    "        # 将嵌入和标签转换为张量\n",
    "        combined_embeddings_tensor = torch.stack(combined_embeddings)\n",
    "        # combined_embeddings_tensor shape : torch.Size([50, 2*graph embedding]) 兩張graph的嵌入拼接起來\n",
    "        self.labels_tensor = torch.tensor(labels).to(self.device)\n",
    "        # labels_tensor shape : torch.Size([50]) 也就是50個graph的label\n",
    "        self.preserve_predict = self.classifier(combined_embeddings_tensor).squeeze()\n",
    "        # preserve_predict shape: torch.Size([50])也就是50個graph預測的label\n",
    "        \n",
    "        self.mlp_label = torch.stack(self.mlp_label, dim=0) # shape: torch.Size([50, 1225])\n",
    "        self.mlp_target = torch.stack(self.mlp_target, dim=0) # shape: torch.Size([50, 1225])\n",
    "\n",
    "        \n",
    "        return self.cosine_similarities, self.preserve_predict, self.labels_tensor, MVC_diff/self.GraphNumber, label_preserve, self.mlp_label, self.mlp_target\n",
    "        \n",
    "        \n",
    "    def init_graph(self):\n",
    "        \"\"\"construct or load training graph and use Node2vec to get node embedding\"\"\"\n",
    "        self.train_graphs, self.train_opt = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50_withOPT.pkl\")\n",
    "        self.create_edge_dict(self.Graphsize)\n",
    "        for i in range(self.GraphNumber):\n",
    "            # p = random.uniform(graph_density[0], graph_density[1])\n",
    "            # G = nx.erdos_renyi_graph(graph_size, p)\n",
    "            G = self.train_graphs[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "            # x = torch.eye(G.number_of_nodes())  # 节点特征\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.dataset.append(data)\n",
    "            \n",
    "    def create_edge_dict(self,graph_size):\n",
    "        \"\"\"mapping edge to index\"\"\"\n",
    "        index = 0\n",
    "        for i in range(graph_size - 1):\n",
    "            for j in range(i + 1, graph_size):\n",
    "                self.whole_edge_set.add((i, j))\n",
    "                self.edge_dict[(i, j)] = index\n",
    "                index += 1\n",
    "    \n",
    "    def calculate_adj_similarity(self,original_graphs, modified_graphs):\n",
    "        \"\"\"calculate the similarity of each edge\"\"\"\n",
    "        similarity = 0\n",
    "        for i in range(len(original_graphs)):\n",
    "            original_graph = original_graphs[i]\n",
    "            original_graph_np = nx.adjacency_matrix(original_graph).todense()\n",
    "            original_graph_np_flatten = np.array(original_graph_np).flatten()\n",
    "            original_tensor = torch.tensor(original_graph_np_flatten).to(self.device)\n",
    "            original_tensor = original_tensor.float().unsqueeze(0)\n",
    "            \n",
    "            modify_graph = modified_graphs[i]\n",
    "            modify_graph_np = nx.adjacency_matrix(modify_graph).todense()\n",
    "            modify_graph_np_flatten = np.array(modify_graph_np).flatten()\n",
    "            modify_tensor = torch.tensor(modify_graph_np_flatten).to(self.device)\n",
    "            modify_tensor = modify_tensor.float().unsqueeze(0) \n",
    "        \n",
    "            cos = nn.CosineSimilarity(dim=1)\n",
    "            similarity += cos(original_tensor, modify_tensor)\n",
    "        \n",
    "        print(f\"similarity: {similarity / len(original_graphs)}\")\n",
    "            \n",
    "    def calculate_MVC(self,graph, UB=9999999, C=set()):\n",
    "        \"\"\"use branch and bound to find out the mvc result\"\"\"\n",
    "        if len(graph.edges()) == 0:\n",
    "            return C\n",
    "\n",
    "        v, _ = max(graph.degree(), key=lambda a: a[1])\n",
    "        # C1 分支：選擇鄰居\n",
    "        C1 = C.copy()\n",
    "        neighbors = set(graph.neighbors(v))\n",
    "        C1.update(neighbors)\n",
    "        graph_1 = graph.copy()\n",
    "        graph_1.remove_nodes_from(neighbors)\n",
    "        if len(C1) < UB:\n",
    "            C1 = self.calculate_MVC(graph_1, UB, C1)\n",
    "\n",
    "        # C2 分支：只選擇該節點\n",
    "        C2 = C.copy()\n",
    "        C2.add(v)\n",
    "        graph_2 = graph.copy()\n",
    "        graph_2.remove_node(v)\n",
    "        if len(C2) < UB:\n",
    "            C2 = self.calculate_MVC(graph_2, min(UB, len(C1)), C2)\n",
    "\n",
    "        return min(C1, C2, key=len)\n",
    "    \n",
    "    def get_graph_embedding(self,embeddings):\n",
    "        \"\"\"average all node embeddings to get graph embedding, embedding 是一個list，每個元素是一個graph的node embedding\"\"\"\n",
    "        graph_embeddings = []\n",
    "        for embedding in embeddings:\n",
    "            graph_embedding = embedding.mean(dim=0)  # 对所有节点嵌入求平均\n",
    "            graph_embeddings.append(graph_embedding)\n",
    "        return torch.stack(graph_embeddings)\n",
    "    \n",
    "    def generate_edge_embeddings(self,data, embedding, graph_emb):\n",
    "        \"\"\"generate and sample edge embeddings for training 需要修改\"\"\"\n",
    "        data= to_networkx(data, to_undirected=True)\n",
    "        edge_set = set(data.edges()) \n",
    "        edge_modify_label = [torch.tensor(0.0).to(self.device) for _ in range(len(self.whole_edge_set))]\n",
    "        edge_modify_softmax = []\n",
    "        edge_pro_list = []\n",
    "        none_edge_pro_list = []\n",
    "        gumbel_modify_edge = []  #紀錄那些邊被修改\n",
    "        for u,v in self.whole_edge_set:\n",
    "            node1_emb = embedding[u]\n",
    "            node2_emb = embedding[v]\n",
    "            if (u,v) in edge_set:\n",
    "                connect_info = torch.tensor([1.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb,connect_info , graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                if modify_pro == 1:\n",
    "                    gumbel_modify_edge.append((u,v))\n",
    "\n",
    "            else:\n",
    "                connect_info = torch.tensor([0.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb, connect_info, graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                none_edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                if modify_pro == 1:\n",
    "                    gumbel_modify_edge.append((u,v))\n",
    "        \n",
    "        \"\"\"計算label不需用gradient\"\"\"\n",
    "        edge_pro_list = sorted(edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        none_edge_pro_list = sorted(none_edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        for i in range(len(edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0).to(self.device)\n",
    "        for i in range(len(none_edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[none_edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0).to(self.device)\n",
    "        # print(f\"len of edge_modify_label : {len of edge_modify_softmax : {len(edge_modify_softmax)}, len(edge_modify_label)}, type of edge_modify_softmax[0] : {type(edge_modify_softmax[0])}, type of edge_modify_label[0] : {type(edge_modify_label[0])}\")\n",
    "        # print(f\"true in edge_modify_softmax : {edge_modify_softmax.count(torch.tensor(1.0))}, true in edge_modify_label : {edge_modify_label.count(torch.tensor(1.0))}, edge_modify_label : { edge_modify_label}\")\n",
    "        \n",
    "        combined_embeddings = gumbel_modify_edge\n",
    "        edge_modify_label = torch.stack(edge_modify_label, dim=0)\n",
    "        edge_modify_softmax = torch.stack(edge_modify_softmax, dim=0)\n",
    "        \n",
    "        return combined_embeddings, edge_modify_label, edge_modify_softmax\n",
    "    \n",
    "    def validation(self):\n",
    "        validation_data, valid_opt, pro = pickle_load(\"/workspace/Synthetic_graph/Validation_graph_200_withOPTPRO.pkl\")\n",
    "        valid_original_embeddings = []\n",
    "        self.valid_dataset = []\n",
    "        self.valid_modified_graphs = []\n",
    "        # 把validation data轉成pyg的data，並透過node2vec得到node feature，再輸入GAT得到node embedding，最後透過get_graph_embedding得到graph embedding\n",
    "        for i in range(len(validation_data)):\n",
    "            G = validation_data[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.valid_dataset.append(data)\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            valid_original_embeddings.append(embedding)\n",
    "        self.valid_graph_embedding = self.get_graph_embedding(valid_original_embeddings)\n",
    "        \n",
    "        # 將每個graph的node embedding和graph embedding還有pyg data輸入generate_edge_embeddings得到要修改的edge，並直接修改成新的graph，用valid_modified_graphs儲存\n",
    "        for emb, data, graph_emb in zip(valid_original_embeddings, self.valid_dataset, self.valid_graph_embedding):\n",
    "            modify_edge, valid_edge_label, valid_edge_softmax = self.generate_edge_embeddings(data, emb, graph_emb) #pyg data是為了知道邊\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            edge_modify_num = 0\n",
    "            for edge in modify_edge:\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    edge_modify_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    edge_modify_num += 1\n",
    "            self.valid_modified_graphs.append(G)\n",
    "        \n",
    "        valid_label_presever = 0\n",
    "        for val_mod_graph, ori_opt in zip(self.valid_modified_graphs, valid_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(val_mod_graph))\n",
    "            if ori_opt == mod_mvc:\n",
    "                valid_label_presever += 1\n",
    "        print(f\"validation label presreved: {valid_label_presever}\")\n",
    "        \n",
    "    def return_graph_embedding(self,G_list):\n",
    "        \"\"\"average all node embeddings to get graph embedding\"\"\"\n",
    "        temp_list = []\n",
    "        for G in G_list:\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64)).to(self.device)\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64)).to(self.device)\n",
    "            edge_index = torch.stack([row, col], dim=0).to(self.device)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float).to(self.device)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np).to(self.device)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            embedding = self.gat(data)\n",
    "            temp_list.append(embedding)\n",
    "        graph_embedding = self.get_graph_embedding(temp_list)\n",
    "        return graph_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel\n",
      "gat.gat1.att_src: requires_grad=True\n",
      "gat.gat1.att_dst: requires_grad=True\n",
      "gat.gat1.bias: requires_grad=True\n",
      "gat.gat1.lin_src.weight: requires_grad=True\n",
      "gat.gat2.att_src: requires_grad=True\n",
      "gat.gat2.att_dst: requires_grad=True\n",
      "gat.gat2.bias: requires_grad=True\n",
      "gat.gat2.lin_src.weight: requires_grad=True\n",
      "mlp.fc1.weight: requires_grad=True\n",
      "mlp.fc1.bias: requires_grad=True\n",
      "mlp.fc2.weight: requires_grad=True\n",
      "mlp.fc2.bias: requires_grad=True\n",
      "mlp.fc3.weight: requires_grad=True\n",
      "mlp.fc3.bias: requires_grad=True\n",
      "mlp.fc4.weight: requires_grad=True\n",
      "mlp.fc4.bias: requires_grad=True\n",
      "mlp.fc5.weight: requires_grad=True\n",
      "mlp.fc5.bias: requires_grad=True\n",
      "classifier.fc1.weight: requires_grad=True\n",
      "classifier.fc1.bias: requires_grad=True\n",
      "classifier.fc2.weight: requires_grad=True\n",
      "classifier.fc2.bias: requires_grad=True\n",
      "classifier.fc3.weight: requires_grad=True\n",
      "classifier.fc3.bias: requires_grad=True\n",
      "classifier.fc4.weight: requires_grad=True\n",
      "classifier.fc4.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_sample_number = 100\n",
    "learning_rate = 0.0001\n",
    "mymodel = Modify_edge(num_features=256, graph_embedding_size=512, epoch=100, lr=learning_rate, modified_edge=edge_sample_number, GraphNumber=50, Graphsize=50, num_heads=4)\n",
    "# mymodel.load_state_dict(torch.load(\"/workspace/Model/20epoch_decrease_edge_choose.pth\"))\n",
    "mymodel = mymodel.to(device)\n",
    "print(\"mymodel\")\n",
    "for name, param in mymodel.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "BCEloss_fn = nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=learning_rate,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_num: 197, delete_num: 474\n",
      "add_num: 221, delete_num: 395\n",
      "add_num: 193, delete_num: 462\n",
      "add_num: 249, delete_num: 385\n",
      "add_num: 477, delete_num: 170\n",
      "add_num: 163, delete_num: 473\n",
      "add_num: 340, delete_num: 276\n",
      "add_num: 390, delete_num: 233\n",
      "add_num: 345, delete_num: 304\n",
      "add_num: 399, delete_num: 251\n",
      "add_num: 225, delete_num: 400\n",
      "add_num: 222, delete_num: 429\n",
      "add_num: 386, delete_num: 245\n",
      "add_num: 239, delete_num: 380\n",
      "add_num: 337, delete_num: 301\n",
      "add_num: 263, delete_num: 384\n",
      "add_num: 237, delete_num: 443\n",
      "add_num: 379, delete_num: 243\n",
      "add_num: 366, delete_num: 270\n",
      "add_num: 246, delete_num: 408\n",
      "add_num: 403, delete_num: 211\n",
      "add_num: 214, delete_num: 459\n",
      "add_num: 289, delete_num: 393\n",
      "add_num: 420, delete_num: 209\n",
      "add_num: 448, delete_num: 200\n",
      "add_num: 432, delete_num: 203\n",
      "add_num: 173, delete_num: 435\n",
      "add_num: 178, delete_num: 466\n",
      "add_num: 433, delete_num: 204\n",
      "add_num: 267, delete_num: 354\n",
      "add_num: 344, delete_num: 279\n",
      "add_num: 256, delete_num: 388\n",
      "add_num: 439, delete_num: 185\n",
      "add_num: 428, delete_num: 176\n",
      "add_num: 204, delete_num: 448\n",
      "add_num: 429, delete_num: 218\n",
      "add_num: 223, delete_num: 391\n",
      "add_num: 399, delete_num: 246\n",
      "add_num: 391, delete_num: 245\n",
      "add_num: 374, delete_num: 243\n",
      "add_num: 291, delete_num: 351\n",
      "add_num: 282, delete_num: 363\n",
      "add_num: 298, delete_num: 345\n",
      "add_num: 273, delete_num: 346\n",
      "add_num: 318, delete_num: 337\n",
      "add_num: 333, delete_num: 296\n",
      "add_num: 468, delete_num: 176\n",
      "add_num: 393, delete_num: 252\n",
      "add_num: 417, delete_num: 219\n",
      "add_num: 380, delete_num: 230\n",
      "similarity: tensor([0.4733], device='cuda:0')\n",
      "label presreved: 4, MVC_diff : 307\n",
      "Epoch: 0, Loss: 9.137884140014648, similarity_weight: 2, similarity_loss: 0.9216845631599426, none_label_preserve: 0.92, preserve_weight: 1, mlp_loss : 51.394283294677734, mlp_loss_weight: 0.05, classifier_loss: 0.7348008751869202, difference_loss: 6.14\n",
      "add_num: 188, delete_num: 422\n",
      "add_num: 249, delete_num: 340\n",
      "add_num: 198, delete_num: 381\n",
      "add_num: 254, delete_num: 371\n",
      "add_num: 468, delete_num: 174\n",
      "add_num: 167, delete_num: 432\n",
      "add_num: 323, delete_num: 270\n",
      "add_num: 402, delete_num: 212\n",
      "add_num: 322, delete_num: 290\n",
      "add_num: 389, delete_num: 209\n",
      "add_num: 210, delete_num: 393\n",
      "add_num: 210, delete_num: 381\n",
      "add_num: 368, delete_num: 234\n",
      "add_num: 243, delete_num: 359\n",
      "add_num: 308, delete_num: 281\n",
      "add_num: 236, delete_num: 353\n",
      "add_num: 231, delete_num: 389\n",
      "add_num: 397, delete_num: 205\n",
      "add_num: 339, delete_num: 237\n",
      "add_num: 213, delete_num: 393\n",
      "add_num: 397, delete_num: 184\n",
      "add_num: 204, delete_num: 418\n",
      "add_num: 250, delete_num: 354\n",
      "add_num: 396, delete_num: 201\n",
      "add_num: 406, delete_num: 184\n",
      "add_num: 417, delete_num: 198\n",
      "add_num: 163, delete_num: 437\n",
      "add_num: 178, delete_num: 400\n",
      "add_num: 412, delete_num: 195\n",
      "add_num: 271, delete_num: 345\n",
      "add_num: 336, delete_num: 300\n",
      "add_num: 249, delete_num: 343\n",
      "add_num: 406, delete_num: 187\n",
      "add_num: 443, delete_num: 172\n",
      "add_num: 199, delete_num: 403\n",
      "add_num: 372, delete_num: 221\n",
      "add_num: 234, delete_num: 362\n",
      "add_num: 387, delete_num: 245\n",
      "add_num: 363, delete_num: 246\n",
      "add_num: 386, delete_num: 229\n",
      "add_num: 263, delete_num: 323\n",
      "add_num: 265, delete_num: 330\n",
      "add_num: 294, delete_num: 330\n",
      "add_num: 267, delete_num: 347\n",
      "add_num: 297, delete_num: 322\n",
      "add_num: 317, delete_num: 300\n",
      "add_num: 451, delete_num: 165\n",
      "add_num: 386, delete_num: 225\n",
      "add_num: 381, delete_num: 230\n",
      "add_num: 377, delete_num: 226\n",
      "similarity: tensor([0.5014], device='cuda:0')\n",
      "label presreved: 4, MVC_diff : 265\n",
      "Epoch: 1, Loss: 8.614893913269043, similarity_weight: 2, similarity_loss: 0.9237423539161682, none_label_preserve: 0.92, preserve_weight: 1, mlp_loss : 49.518367767333984, mlp_loss_weight: 0.05, classifier_loss: 0.7214905619621277, difference_loss: 5.3\n",
      "add_num: 184, delete_num: 406\n",
      "add_num: 233, delete_num: 371\n",
      "add_num: 214, delete_num: 387\n",
      "add_num: 232, delete_num: 330\n",
      "add_num: 438, delete_num: 159\n",
      "add_num: 147, delete_num: 428\n",
      "add_num: 328, delete_num: 246\n",
      "add_num: 373, delete_num: 184\n",
      "add_num: 281, delete_num: 278\n",
      "add_num: 386, delete_num: 200\n",
      "add_num: 210, delete_num: 359\n",
      "add_num: 195, delete_num: 375\n",
      "add_num: 391, delete_num: 228\n",
      "add_num: 231, delete_num: 341\n",
      "add_num: 293, delete_num: 251\n",
      "add_num: 229, delete_num: 330\n",
      "add_num: 201, delete_num: 364\n",
      "add_num: 353, delete_num: 207\n",
      "add_num: 346, delete_num: 246\n",
      "add_num: 213, delete_num: 361\n",
      "add_num: 384, delete_num: 204\n",
      "add_num: 199, delete_num: 399\n",
      "add_num: 241, delete_num: 341\n",
      "add_num: 380, delete_num: 184\n",
      "add_num: 431, delete_num: 178\n",
      "add_num: 393, delete_num: 187\n",
      "add_num: 158, delete_num: 403\n",
      "add_num: 158, delete_num: 428\n",
      "add_num: 401, delete_num: 168\n",
      "add_num: 251, delete_num: 309\n",
      "add_num: 329, delete_num: 258\n",
      "add_num: 225, delete_num: 346\n",
      "add_num: 433, delete_num: 169\n",
      "add_num: 425, delete_num: 190\n",
      "add_num: 192, delete_num: 390\n",
      "add_num: 378, delete_num: 199\n",
      "add_num: 209, delete_num: 349\n",
      "add_num: 359, delete_num: 231\n",
      "add_num: 362, delete_num: 228\n",
      "add_num: 356, delete_num: 245\n",
      "add_num: 249, delete_num: 311\n",
      "add_num: 239, delete_num: 327\n",
      "add_num: 274, delete_num: 307\n",
      "add_num: 255, delete_num: 329\n",
      "add_num: 291, delete_num: 289\n",
      "add_num: 272, delete_num: 271\n",
      "add_num: 442, delete_num: 159\n",
      "add_num: 379, delete_num: 206\n",
      "add_num: 364, delete_num: 205\n",
      "add_num: 371, delete_num: 216\n",
      "similarity: tensor([0.5232], device='cuda:0')\n",
      "label presreved: 6, MVC_diff : 272\n",
      "Epoch: 2, Loss: 8.588825225830078, similarity_weight: 2, similarity_loss: 0.9358729124069214, none_label_preserve: 0.88, preserve_weight: 1, mlp_loss : 48.20408248901367, mlp_loss_weight: 0.05, classifier_loss: 0.706874668598175, difference_loss: 5.44\n",
      "add_num: 165, delete_num: 366\n",
      "add_num: 216, delete_num: 331\n",
      "add_num: 190, delete_num: 390\n",
      "add_num: 230, delete_num: 304\n",
      "add_num: 396, delete_num: 144\n",
      "add_num: 131, delete_num: 403\n",
      "add_num: 305, delete_num: 235\n",
      "add_num: 348, delete_num: 186\n",
      "add_num: 304, delete_num: 258\n",
      "add_num: 352, delete_num: 190\n",
      "add_num: 202, delete_num: 352\n",
      "add_num: 200, delete_num: 329\n",
      "add_num: 333, delete_num: 217\n",
      "add_num: 217, delete_num: 327\n",
      "add_num: 317, delete_num: 259\n",
      "add_num: 254, delete_num: 350\n",
      "add_num: 199, delete_num: 337\n",
      "add_num: 328, delete_num: 195\n",
      "add_num: 333, delete_num: 222\n",
      "add_num: 199, delete_num: 336\n",
      "add_num: 340, delete_num: 187\n",
      "add_num: 199, delete_num: 352\n",
      "add_num: 238, delete_num: 314\n",
      "add_num: 345, delete_num: 203\n",
      "add_num: 358, delete_num: 184\n",
      "add_num: 363, delete_num: 176\n",
      "add_num: 171, delete_num: 381\n",
      "add_num: 161, delete_num: 400\n",
      "add_num: 363, delete_num: 180\n",
      "add_num: 243, delete_num: 302\n",
      "add_num: 301, delete_num: 244\n",
      "add_num: 219, delete_num: 320\n",
      "add_num: 360, delete_num: 161\n",
      "add_num: 399, delete_num: 167\n",
      "add_num: 180, delete_num: 366\n",
      "add_num: 395, delete_num: 194\n",
      "add_num: 208, delete_num: 319\n",
      "add_num: 319, delete_num: 203\n",
      "add_num: 311, delete_num: 224\n",
      "add_num: 355, delete_num: 207\n",
      "add_num: 263, delete_num: 286\n",
      "add_num: 255, delete_num: 310\n",
      "add_num: 268, delete_num: 309\n",
      "add_num: 238, delete_num: 299\n",
      "add_num: 257, delete_num: 266\n",
      "add_num: 299, delete_num: 274\n",
      "add_num: 397, delete_num: 139\n",
      "add_num: 352, delete_num: 204\n",
      "add_num: 349, delete_num: 186\n",
      "add_num: 378, delete_num: 206\n",
      "similarity: tensor([0.5470], device='cuda:0')\n",
      "label presreved: 5, MVC_diff : 229\n",
      "Epoch: 3, Loss: 8.08847427368164, similarity_weight: 2, similarity_loss: 0.9388651251792908, none_label_preserve: 0.9, preserve_weight: 1, mlp_loss : 46.55183792114258, mlp_loss_weight: 0.05, classifier_loss: 0.6931514739990234, difference_loss: 4.58\n",
      "add_num: 147, delete_num: 377\n",
      "add_num: 195, delete_num: 284\n",
      "add_num: 179, delete_num: 337\n",
      "add_num: 205, delete_num: 285\n",
      "add_num: 406, delete_num: 140\n",
      "add_num: 144, delete_num: 345\n",
      "add_num: 305, delete_num: 213\n",
      "add_num: 330, delete_num: 178\n",
      "add_num: 284, delete_num: 243\n",
      "add_num: 317, delete_num: 186\n",
      "add_num: 197, delete_num: 309\n",
      "add_num: 189, delete_num: 336\n",
      "add_num: 311, delete_num: 198\n",
      "add_num: 238, delete_num: 311\n",
      "add_num: 268, delete_num: 252\n",
      "add_num: 229, delete_num: 313\n",
      "add_num: 182, delete_num: 320\n",
      "add_num: 318, delete_num: 211\n",
      "add_num: 294, delete_num: 200\n",
      "add_num: 199, delete_num: 323\n",
      "add_num: 364, delete_num: 169\n",
      "add_num: 179, delete_num: 332\n",
      "add_num: 246, delete_num: 304\n",
      "add_num: 342, delete_num: 178\n",
      "add_num: 356, delete_num: 165\n",
      "add_num: 349, delete_num: 167\n",
      "add_num: 135, delete_num: 378\n",
      "add_num: 122, delete_num: 371\n",
      "add_num: 336, delete_num: 165\n",
      "add_num: 227, delete_num: 290\n",
      "add_num: 275, delete_num: 231\n",
      "add_num: 224, delete_num: 331\n",
      "add_num: 339, delete_num: 175\n",
      "add_num: 383, delete_num: 145\n",
      "add_num: 166, delete_num: 355\n",
      "add_num: 373, delete_num: 166\n",
      "add_num: 184, delete_num: 326\n",
      "add_num: 312, delete_num: 195\n",
      "add_num: 301, delete_num: 220\n",
      "add_num: 344, delete_num: 189\n",
      "add_num: 253, delete_num: 284\n",
      "add_num: 236, delete_num: 297\n",
      "add_num: 249, delete_num: 260\n",
      "add_num: 228, delete_num: 299\n",
      "add_num: 260, delete_num: 274\n",
      "add_num: 253, delete_num: 269\n",
      "add_num: 385, delete_num: 130\n",
      "add_num: 326, delete_num: 196\n",
      "add_num: 325, delete_num: 189\n",
      "add_num: 297, delete_num: 202\n"
     ]
    }
   ],
   "source": [
    "diff_weight = 0.5 # MVC修改前後的差異\n",
    "similarity_weight = 2 # 修改前後的圖的相似度\n",
    "preserve_weight = 1 # 保留原本的label\n",
    "classification_weight = 1 # 用來判定graph的result是否有相同的MVC\n",
    "mlp_loss_weight = 0.05\n",
    "# mymodel.load_state_dict(torch.load(\"/workspace/Model/30epoch_decrease_similarity.pth\"))\n",
    "\n",
    "for epoch in range(30):\n",
    "    \n",
    "    mymodel.train()\n",
    "    similarity_loss , preserve_predict, labels_tensor, difference_loss, label_preserve, mlp_label, mlp_target = mymodel()\n",
    "        \n",
    "    mlp_loss = BCEloss_fn(mlp_target, mlp_label)   \n",
    "    \n",
    "    classifier_loss = criterion(preserve_predict, labels_tensor.float())\n",
    "    \n",
    "    none_preserve_loss = (mymodel.GraphNumber-label_preserve) /  mymodel.GraphNumber\n",
    "    \n",
    "    loss = classifier_loss * classification_weight + similarity_loss * similarity_weight + none_preserve_loss * preserve_weight + mlp_loss * mlp_loss_weight + difference_loss * diff_weight\n",
    "    \n",
    "    # loss = none_preserve_loss * preserve_weight + mlp_loss * mlp_loss_weight + difference_loss * diff_weight\n",
    "    \n",
    "    # loss = similarity_loss * similarity_weight + none_preserve_loss * preserve_weight + difference_loss * diff_weight\n",
    "    \n",
    "    # if epoch < 25:\n",
    "    #     mlp_loss_weight -= 0.01\n",
    "    \n",
    "    # if epoch < 30 :\n",
    "    #     similarity_weight += 0.01\n",
    "    #     preserve_weight += 0.02\n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # for name, param in mymodel.named_parameters():\n",
    "    #     if param.grad is not None:\n",
    "    #         print(f\"Gradient of {name}: {param.grad.norm()}\")\n",
    "    #     else:\n",
    "    #         print(f\"Gradient of {name}: None\")\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, similarity_weight: {similarity_weight}, similarity_loss: {similarity_loss.item()}, none_label_preserve: {none_preserve_loss}, preserve_weight: {preserve_weight}, mlp_loss : {mlp_loss.item()}, mlp_loss_weight: {mlp_loss_weight}, classifier_loss: {classifier_loss.item()}, difference_loss: {difference_loss}\")\n",
    "    # if epoch % 2 == 0:\n",
    "    #     print(\"validation\")\n",
    "    #     mymodel.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         mymodel.validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp loss 的用途是減少邊的修改\n",
    "similarity loss的用途是增加差異度\n",
    "classifier loss 是用來判定修改後的圖與修改前的圖是否MVC有改變\n",
    "difference loss 是用來表示50個training graph在這epoch的MVC差異\n",
    "None preserve loss 是計數器，看label preserve的數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mymodel.state_dict(), \"/workspace/Model/30epoch_decrease_similarity.pth\") #similarity: tensor([0.4935], device='cuda:0') similarity_loss: 0.06613559275865555 label presreved: 3, MVC_diff : 249"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
