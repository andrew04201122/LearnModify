{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import random\n",
    "from heapdict import heapdict\n",
    "from node2vec import Node2Vec\n",
    "import argparse\n",
    "import torch.nn.init as init\n",
    "from utils import *\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义GCN模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_features, graph_embedding_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 128)\n",
    "        self.conv2 = GCNConv(128, graph_embedding_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定义GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_heads=4, graph_embedding_size=256):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(num_features, 512, heads=num_heads, dropout=0.2)\n",
    "        self.gat2 = GATConv(512 * num_heads, graph_embedding_size, heads=1, concat=False, dropout=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定義用來決定edge是否修改的MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "class GCN_edge_modify(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels = 512):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # 最后一层，用于产生最终输出\n",
    "        self.out = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "class MLPClassifier(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 128)          # 第二层\n",
    "        self.fc3 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))        # 使用sigmoid确保输出在0到1之间\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modify_edge(nn.Module):\n",
    "    def __init__(self, num_features, graph_embedding_size, epoch = 100, lr = 0.0001, modified_edge = 30, GraphNumber = 50, Graphsize = 50, num_heads = 4):\n",
    "        super(Modify_edge, self).__init__()\n",
    "        self.connect_info_num = 5\n",
    "        self.gat = GAT(num_features=num_features + 1, num_heads=num_heads, graph_embedding_size = graph_embedding_size)  # 根据需要调整头数\n",
    "        self.mlp = MLP(input_size=3 * graph_embedding_size + self.connect_info_num)\n",
    "        self.classifier = MLPClassifier(input_size=2 * graph_embedding_size)\n",
    "        self.modified_edge = modified_edge\n",
    "        self.lr = lr\n",
    "        self.GraphNumber = GraphNumber\n",
    "        self.Graphsize = Graphsize\n",
    "        self.Node2Vec_feature = num_features\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.best_preserve = 0\n",
    "        \n",
    "    def forward(self):\n",
    "        self.modified_graphs = []\n",
    "        self.edge_dict = {}\n",
    "        self.whole_edge_set = set()\n",
    "        self.dataset = []\n",
    "        self.init_graph()  ## create self.dataset\n",
    "        \n",
    "        original_embeddings = []\n",
    "        for data in self.dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            original_embeddings.append(embedding)\n",
    "        self.original_graph_embeddings = self.get_graph_embedding(original_embeddings)\n",
    "        \n",
    "        for emb, data, graph_emb in zip(original_embeddings, self.dataset, self.original_graph_embeddings):\n",
    "            modify_edge = self.generate_edge_embeddings(data, emb, graph_emb)\n",
    "            add_num = 0\n",
    "            delete_num = 0\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            G_edge_set = set(G.edges())\n",
    "            for decision in modify_edge:  # decision: (probabilities,(u,v))\n",
    "                edge = decision[1]\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    delete_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    add_num += 1\n",
    "            # print(f\"modify num : {len(set(G.edges()) ^ G_edge_set)}, add num: {add_num}, delete num: {delete_num}\")\n",
    "            self.modified_graphs.append(G)\n",
    "        \n",
    "        self.modified_dataset = []  #type pyg\n",
    "        for G in self.modified_graphs:\n",
    "            # 从 NetworkX 图创建边索引\n",
    "            edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            # 使用单位矩阵作为节点特征\n",
    "            # x = torch.eye(G.number_of_nodes())\n",
    "            \n",
    "            # 创建 Data 对象\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.modified_dataset.append(data)  \n",
    "            \n",
    "        modified_embeddings = []\n",
    "        for data in self.modified_dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            modified_embeddings.append(embedding)  \n",
    "        self.modified_graph_embeddings = self.get_graph_embedding(modified_embeddings)\n",
    "        \n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        self.cosine_similarities = cos(self.modified_graph_embeddings, self.original_graph_embeddings).mean()\n",
    "        \n",
    "        # similarity = torch.zeros(1, requires_grad=True).to(self.device)\n",
    "        # for i in range(self.GraphNumber):\n",
    "        #     A1 = nx.adjacency_matrix(self.train_graphs[i]).toarray()\n",
    "        #     A2 = nx.adjacency_matrix(self.modified_graphs[i]).toarray()\n",
    "        #     tensor1 = torch.from_numpy(A1).float().view(-1)\n",
    "        #     tensor2 = torch.from_numpy(A2).float().view(-1)\n",
    "        #     cos = nn.CosineSimilarity(dim=0)\n",
    "        #     print(f\"cosine similarity: {cos(tensor1, tensor2)}\")\n",
    "        #     similarity = similarity + cos(tensor1, tensor2)\n",
    "        \n",
    "            \n",
    "        # temp_cosine_similarities = similarity / self.GraphNumber\n",
    "        # print(f\"temp_cosine_similarities: {temp_cosine_similarities.item()}\")\n",
    "            \n",
    "        labels = []\n",
    "        MVC_diff = 0\n",
    "        for mod_graph, orig_mvc in zip(self.modified_graphs, self.train_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(mod_graph))\n",
    "            # print(f\"mod_mvc: {mod_mvc}, ori_mvc: {orig_mvc}, diff: {abs(mod_mvc - orig_mvc)}\")\n",
    "            MVC_diff = MVC_diff + abs(mod_mvc - orig_mvc) * abs(mod_mvc - orig_mvc)\n",
    "            label = 1 if mod_mvc == orig_mvc else 0\n",
    "            labels.append(label)\n",
    "        print(f\"label presreved: {labels.count(1)}, MVC_diff : {MVC_diff}\")\n",
    "        label_preserve = labels.count(1)\n",
    "        if label_preserve > self.best_preserve:\n",
    "            self.best_preserve = label_preserve\n",
    "            torch.save(self.state_dict(), \"/workspace/Model/Modify_edge_model_1.pth\")\n",
    "        combined_embeddings = [torch.cat((mod_emb, orig_emb)) for mod_emb, orig_emb in zip(self.modified_graph_embeddings, self.original_graph_embeddings)]\n",
    "        # 将嵌入和标签转换为张量\n",
    "        combined_embeddings_tensor = torch.stack(combined_embeddings)\n",
    "        # combined_embeddings_tensor shape : torch.Size([50, 2*graph embedding]) 兩張graph的嵌入拼接起來\n",
    "        self.labels_tensor = torch.tensor(labels).to(self.device)\n",
    "        # labels_tensor shape : torch.Size([50]) 也就是50個graph的label\n",
    "        self.preserve_predict = self.classifier(combined_embeddings_tensor).squeeze()\n",
    "        # preserve_predict shape: torch.Size([50])也就是50個graph預測的label\n",
    "        return self.cosine_similarities, self.preserve_predict, self.labels_tensor, MVC_diff/self.GraphNumber, label_preserve\n",
    "        \n",
    "        \n",
    "    def init_graph(self):\n",
    "        \"\"\"construct or load training graph and use Node2vec to get node embedding\"\"\"\n",
    "        self.train_graphs, self.train_opt = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50_withOPT.pkl\")\n",
    "        self.create_edge_dict(self.Graphsize)\n",
    "        for i in range(self.GraphNumber):\n",
    "            # p = random.uniform(graph_density[0], graph_density[1])\n",
    "            # G = nx.erdos_renyi_graph(graph_size, p)\n",
    "            G = self.train_graphs[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "            # x = torch.eye(G.number_of_nodes())  # 节点特征\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.dataset.append(data)\n",
    "            \n",
    "    def create_edge_dict(self,graph_size):\n",
    "        \"\"\"mapping edge to index\"\"\"\n",
    "        index = 0\n",
    "        for i in range(graph_size - 1):\n",
    "            for j in range(i + 1, graph_size):\n",
    "                self.whole_edge_set.add((i, j))\n",
    "                self.edge_dict[(i, j)] = index\n",
    "                index += 1\n",
    "        \n",
    "    def calculate_MVC(self,graph, UB=9999999, C=set()):\n",
    "        \"\"\"use branch and bound to find out the mvc result\"\"\"\n",
    "        if len(graph.edges()) == 0:\n",
    "            return C\n",
    "\n",
    "        v, _ = max(graph.degree(), key=lambda a: a[1])\n",
    "        # C1 分支：選擇鄰居\n",
    "        C1 = C.copy()\n",
    "        neighbors = set(graph.neighbors(v))\n",
    "        C1.update(neighbors)\n",
    "        graph_1 = graph.copy()\n",
    "        graph_1.remove_nodes_from(neighbors)\n",
    "        if len(C1) < UB:\n",
    "            C1 = self.calculate_MVC(graph_1, UB, C1)\n",
    "\n",
    "        # C2 分支：只選擇該節點\n",
    "        C2 = C.copy()\n",
    "        C2.add(v)\n",
    "        graph_2 = graph.copy()\n",
    "        graph_2.remove_node(v)\n",
    "        if len(C2) < UB:\n",
    "            C2 = self.calculate_MVC(graph_2, min(UB, len(C1)), C2)\n",
    "\n",
    "        return min(C1, C2, key=len)\n",
    "    \n",
    "    def get_graph_embedding(self,embeddings):\n",
    "        \"\"\"average all node embeddings to get graph embedding, embedding 是一個list，每個元素是一個graph的node embedding\"\"\"\n",
    "        graph_embeddings = []\n",
    "        for embedding in embeddings:\n",
    "            graph_embedding = embedding.mean(dim=0)  # 对所有节点嵌入求平均\n",
    "            graph_embeddings.append(graph_embedding)\n",
    "        return torch.stack(graph_embeddings)\n",
    "    \n",
    "    def generate_edge_embeddings(self,data, embedding, graph_emb):\n",
    "        \"\"\"generate and sample edge embeddings for training 需要修改\"\"\"\n",
    "        data= to_networkx(data, to_undirected=True)\n",
    "        edge_set = set(data.edges()) \n",
    "        combined_embeddings = []\n",
    "        edge_pro_list = []\n",
    "        none_edge_pro_list = []\n",
    "        # print(f\"len of edge_set: {len(edge_set)}, len of whole_edge_set: {len(self.whole_edge_set)}, len of none edge: {len(self.whole_edge_set) - len(edge_set)}\")\n",
    "        for u,v in self.whole_edge_set:\n",
    "            node1_emb = embedding[u]\n",
    "            node2_emb = embedding[v]\n",
    "            if (u,v) in edge_set:\n",
    "                connect_info = torch.tensor([1.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb,connect_info , graph_emb])\n",
    "                probabilities = self.mlp(node_pair_emb).squeeze()\n",
    "                edge_pro_list.append((probabilities,(u,v)))\n",
    "            else:\n",
    "                connect_info = torch.tensor([0.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb, connect_info, graph_emb])\n",
    "                probabilities = self.mlp(node_pair_emb).squeeze()\n",
    "                none_edge_pro_list.append((probabilities.item(),(u,v)))\n",
    "        edge_pro_list = sorted(edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        none_edge_pro_list = sorted(none_edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        # print(pro_list)\n",
    "        combined_embeddings = edge_pro_list[:self.modified_edge] + none_edge_pro_list[:self.modified_edge]\n",
    "        return combined_embeddings\n",
    "    \n",
    "    def validation(self):\n",
    "        validation_data, valid_opt, pro = pickle_load(\"/workspace/Synthetic_graph/Validation_graph_200_withOPTPRO.pkl\")\n",
    "        valid_original_embeddings = []\n",
    "        self.valid_dataset = []\n",
    "        self.valid_modified_graphs = []\n",
    "        # 把validation data轉成pyg的data，並透過node2vec得到node feature，再輸入GAT得到node embedding，最後透過get_graph_embedding得到graph embedding\n",
    "        for i in range(len(validation_data)):\n",
    "            G = validation_data[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.valid_dataset.append(data)\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            valid_original_embeddings.append(embedding)\n",
    "        self.valid_graph_embedding = self.get_graph_embedding(valid_original_embeddings)\n",
    "        \n",
    "        # 將每個graph的node embedding和graph embedding還有pyg data輸入generate_edge_embeddings得到要修改的edge，並直接修改成新的graph，用valid_modified_graphs儲存\n",
    "        for emb, data, graph_emb in zip(valid_original_embeddings, self.valid_dataset, self.valid_graph_embedding):\n",
    "            modify_edge = self.generate_edge_embeddings(data, emb, graph_emb) #pyg data是為了知道邊\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            for decision in modify_edge:\n",
    "                edge = decision[1]\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "            self.valid_modified_graphs.append(G)\n",
    "        \n",
    "        valid_label_presever = 0\n",
    "        for val_mod_graph, ori_opt in zip(self.valid_modified_graphs, valid_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(val_mod_graph))\n",
    "            if ori_opt == mod_mvc:\n",
    "                valid_label_presever += 1\n",
    "        print(f\"validation label presreved: {valid_label_presever}\")\n",
    "        \n",
    "    def return_graph_embedding(self,G):\n",
    "        \"\"\"average all node embeddings to get graph embedding\"\"\"\n",
    "        adj_matrix = nx.adjacency_matrix(G)\n",
    "        adj_matrix = coo_matrix(adj_matrix)\n",
    "        row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "        col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "        InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "        # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "        node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "        node2vec_features_np = np.array(node2vec_embeddings)\n",
    "        degrees = nx.degree(G)\n",
    "        degree_values = [deg for node, deg in degrees]\n",
    "        degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "        degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "        degree_features = degree_normalized.view(-1, 1)\n",
    "        node2vec_features = torch.tensor(node2vec_features_np)\n",
    "        combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "        data = Data(x=combined_features, edge_index=edge_index)\n",
    "        embedding = self.gat(data)\n",
    "        graph_embedding = self.get_graph_embedding([embedding])\n",
    "        return graph_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_sample_number = 50\n",
    "learning_rate = 0.0001\n",
    "mymodel = Modify_edge(num_features=128, graph_embedding_size=256, epoch=100, lr=learning_rate, modified_edge=edge_sample_number, GraphNumber=50, Graphsize=50, num_heads=4)\n",
    "mymodel.load_state_dict(torch.load(\"/workspace//backup/Modify_edge_model.pth\"))\n",
    "mymodel = mymodel.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=learning_rate,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label presreved: 27, MVC_diff : 29\n",
      "Epoch: 0, Loss: 2.66321063041687, similarity_loss: 0.9297683238983154, difference_loss: 0.58, none_label_preserve: 0.46000000834465027, classifier_loss: 0.6934423446655273\n",
      "validation\n",
      "validation label presreved: 126\n",
      "label presreved: 21, MVC_diff : 32\n",
      "Epoch: 1, Loss: 2.829472541809082, similarity_loss: 0.9083225727081299, difference_loss: 0.64, none_label_preserve: 0.5799999833106995, classifier_loss: 0.701150119304657\n",
      "label presreved: 22, MVC_diff : 37\n",
      "Epoch: 2, Loss: 2.876267194747925, similarity_loss: 0.88071608543396, difference_loss: 0.74, none_label_preserve: 0.5600000023841858, classifier_loss: 0.6955511569976807\n",
      "validation\n",
      "validation label presreved: 113\n",
      "label presreved: 23, MVC_diff : 33\n",
      "Epoch: 3, Loss: 2.714562177658081, similarity_loss: 0.8201804161071777, difference_loss: 0.66, none_label_preserve: 0.5400000214576721, classifier_loss: 0.6943817138671875\n",
      "label presreved: 16, MVC_diff : 52\n",
      "Epoch: 4, Loss: 3.157338857650757, similarity_loss: 0.7432281970977783, difference_loss: 1.04, none_label_preserve: 0.6800000071525574, classifier_loss: 0.6941105723381042\n",
      "validation\n",
      "validation label presreved: 72\n",
      "label presreved: 19, MVC_diff : 60\n",
      "Epoch: 5, Loss: 3.1297783851623535, similarity_loss: 0.618739902973175, difference_loss: 1.2, none_label_preserve: 0.6200000047683716, classifier_loss: 0.6910383701324463\n",
      "label presreved: 16, MVC_diff : 75\n",
      "Epoch: 6, Loss: 3.292600631713867, similarity_loss: 0.4173325002193451, difference_loss: 1.5, none_label_preserve: 0.6800000071525574, classifier_loss: 0.6952680945396423\n",
      "validation\n",
      "validation label presreved: 83\n",
      "label presreved: 21, MVC_diff : 50\n",
      "Epoch: 7, Loss: 2.52217173576355, similarity_loss: 0.24760447442531586, difference_loss: 1.0, none_label_preserve: 0.5799999833106995, classifier_loss: 0.6945673823356628\n",
      "label presreved: 20, MVC_diff : 45\n",
      "Epoch: 8, Loss: 2.294404983520508, similarity_loss: 0.09561676532030106, difference_loss: 0.9, none_label_preserve: 0.6000000238418579, classifier_loss: 0.6987882852554321\n",
      "validation\n",
      "validation label presreved: 96\n",
      "label presreved: 19, MVC_diff : 74\n",
      "Epoch: 9, Loss: 2.910482883453369, similarity_loss: 0.11065713316202164, difference_loss: 1.48, none_label_preserve: 0.6200000047683716, classifier_loss: 0.6998255848884583\n",
      "label presreved: 17, MVC_diff : 71\n",
      "Epoch: 10, Loss: 2.9246866703033447, similarity_loss: 0.1438508927822113, difference_loss: 1.42, none_label_preserve: 0.6600000262260437, classifier_loss: 0.7008357048034668\n",
      "validation\n",
      "validation label presreved: 84\n",
      "label presreved: 20, MVC_diff : 51\n",
      "Epoch: 11, Loss: 2.512643814086914, similarity_loss: 0.1946028470993042, difference_loss: 1.02, none_label_preserve: 0.6000000238418579, classifier_loss: 0.6980408430099487\n",
      "label presreved: 19, MVC_diff : 54\n",
      "Epoch: 12, Loss: 2.5832102298736572, similarity_loss: 0.18384185433387756, difference_loss: 1.08, none_label_preserve: 0.6200000047683716, classifier_loss: 0.6993683576583862\n",
      "validation\n",
      "validation label presreved: 85\n"
     ]
    }
   ],
   "source": [
    "diff_weight = 1 # MVC修改前後的差異\n",
    "similarity_weight = 1 # 修改前後的圖的相似度\n",
    "preserve_weight = 1 # 保留原本的label\n",
    "classification_weight = 1 # 用來判定graph的result是否有相同的MVC\n",
    "for epoch in range(41):\n",
    "    mymodel.train()\n",
    "    similarity_loss , preserve_predict, labels_tensor, difference_loss, label_preserve = mymodel()\n",
    "    classifier_loss = criterion(preserve_predict, labels_tensor.float())\n",
    "    \n",
    "    total_labels_tensor = torch.tensor(mymodel.GraphNumber, dtype=torch.float32)\n",
    "    label_preserve_tensor = torch.tensor(label_preserve, dtype=torch.float32, requires_grad=True)\n",
    "    none_preserve_loss = (total_labels_tensor-label_preserve_tensor) / total_labels_tensor\n",
    "    \n",
    "    loss = classifier_loss * classification_weight + similarity_loss * similarity_weight + difference_loss * diff_weight + none_preserve_loss * preserve_weight\n",
    "    \n",
    "    # none_preserve = (mymodel.GraphNumber - label_preserve) / mymodel.GraphNumber\n",
    "    # loss = similarity_loss * similarity_weight + difference_loss * diff_weight + none_preserve * preserve_weight\n",
    "      \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, similarity_loss: {similarity_loss.item()}, difference_loss: {difference_loss}, none_label_preserve: {none_preserve_loss.item()}, classifier_loss: {classifier_loss.item()}\")\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"validation\")\n",
    "        mymodel.eval()\n",
    "        with torch.no_grad():\n",
    "            mymodel.validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
