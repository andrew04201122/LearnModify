{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import random\n",
    "from heapdict import heapdict\n",
    "\n",
    "# 定义GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_heads=8):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(num_features, 16, heads=num_heads, dropout=0.6)\n",
    "        self.gat2 = GATConv(16 * num_heads, 16, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定义MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # 第一层\n",
    "        self.fc2 = nn.Linear(64, 32)          # 第二层\n",
    "        self.fc3 = nn.Linear(32, 1)           # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))        # 使用sigmoid确保输出在0到1之间\n",
    "        return x\n",
    "\n",
    "# 函数以采样与边数相同数量的不存在的边\n",
    "def sample_non_edges(dataset):\n",
    "    non_edges_samples = []\n",
    "\n",
    "    for data in dataset:\n",
    "        num_nodes = data.num_nodes\n",
    "        all_possible_pairs = {(i, j) for i in range(num_nodes) for j in range(num_nodes) if i != j}\n",
    "        existing_edges = {tuple(edge) for edge in data.edge_index.t().tolist()}\n",
    "        non_edges = list(all_possible_pairs - existing_edges)\n",
    "        num_edges = data.edge_index.size(1)\n",
    "        sampled_non_edges = random.sample(non_edges, num_edges)\n",
    "\n",
    "        non_edges_samples.append(sampled_non_edges)\n",
    "\n",
    "    return non_edges_samples\n",
    "\n",
    "def generate_edge_embeddings(dataset, embeddings):\n",
    "    combined_embeddings_per_graph = []\n",
    "\n",
    "    for data, embedding in zip(dataset, embeddings):\n",
    "        edge_embeddings = []\n",
    "        non_edge_embeddings = []\n",
    "        existing_edges = set()\n",
    "\n",
    "        # 处理存在的边\n",
    "        for edge in data.edge_index.t().numpy():\n",
    "            edge = tuple(sorted(edge))  # 确保边的一致方向\n",
    "            if edge not in existing_edges:\n",
    "                node1_emb = embedding[edge[0]]\n",
    "                node2_emb = embedding[edge[1]]\n",
    "                edge_emb = torch.cat([node1_emb, node2_emb, torch.tensor([1.0])])  # 连接节点嵌入并添加标签1\n",
    "                edge_embeddings.append(edge_emb)\n",
    "                existing_edges.add(edge)\n",
    "        # print(existing_edges)\n",
    "        # 处理不存在的边\n",
    "        sampled_non_edges = sample_non_edges([data])[0]\n",
    "        for non_edge in sampled_non_edges:\n",
    "            non_edge = tuple(sorted(non_edge))  # 确保边的一致方向\n",
    "            if non_edge not in existing_edges:\n",
    "                node1_emb = embedding[non_edge[0]]\n",
    "                node2_emb = embedding[non_edge[1]]\n",
    "                non_edge_emb = torch.cat([node1_emb, node2_emb, torch.tensor([0.0])])  # 连接节点嵌入并添加标签0\n",
    "                non_edge_embeddings.append(non_edge_emb)\n",
    "        combined_embeddings = edge_embeddings + non_edge_embeddings\n",
    "        combined_embeddings_per_graph.append(combined_embeddings)\n",
    "\n",
    "    return combined_embeddings_per_graph\n",
    "\n",
    "def calculate_MVC(graph, UB=9999999, C=set()):\n",
    "    \"\"\"use branch and bound to find out the mvc result\"\"\"\n",
    "    if len(graph.edges()) == 0:\n",
    "        return C\n",
    "\n",
    "    v, _ = max(graph.degree(), key=lambda a: a[1])\n",
    "\n",
    "    # C1 分支：選擇鄰居\n",
    "    C1 = C.copy()\n",
    "    neighbors = set(graph.neighbors(v))\n",
    "    C1.update(neighbors)\n",
    "    graph_1 = graph.copy()\n",
    "    graph_1.remove_nodes_from(neighbors)\n",
    "    if len(C1) < UB:\n",
    "        C1 = calculate_MVC(graph_1, UB, C1)\n",
    "\n",
    "    # C2 分支：只選擇該節點\n",
    "    C2 = C.copy()\n",
    "    C2.add(v)\n",
    "    graph_2 = graph.copy()\n",
    "    graph_2.remove_node(v)\n",
    "    if len(C2) < UB:\n",
    "        C2 = calculate_MVC(graph_2, min(UB, len(C1)), C2)\n",
    "\n",
    "    return min(C1, C2, key=len)\n",
    "\n",
    "# 计算图级嵌入：对所有节点的嵌入进行平均\n",
    "def get_graph_embedding(embeddings):\n",
    "    graph_embeddings = []\n",
    "    for embedding in embeddings:\n",
    "        graph_embedding = embedding.mean(dim=0)  # 对所有节点嵌入求平均\n",
    "        graph_embeddings.append(graph_embedding)\n",
    "    return torch.stack(graph_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "創建資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建50张图的数据集\n",
    "dataset = []\n",
    "\n",
    "for _ in range(50):\n",
    "    G = nx.erdos_renyi_graph(50, 0.15)\n",
    "    adj_matrix = nx.adjacency_matrix(G)\n",
    "    adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "    row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "    col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    x = torch.eye(G.number_of_nodes())  # 节点特征\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    dataset.append(data)\n",
    "\n",
    "model = GAT(num_features=50)\n",
    "\n",
    "# 获取节点嵌入（不训练模型）\n",
    "model.eval()\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for data in dataset:\n",
    "        embedding = model(data) # [num_nodes, num_features] = [50, 16]\n",
    "        embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "產生edge embedding，並透過MLP決定哪幾個邊要修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每张图的边和非边嵌入 \n",
    "# combined_embeddings_per_graph = [num_graphs, num_edges + num_non_edges, embedding_size] = [50, edge num + non edge num, 33]\n",
    "combined_embeddings_per_graph = generate_edge_embeddings(dataset, embeddings)\n",
    "\n",
    "# 假设每个节点嵌入的大小为16\n",
    "node_embedding_size = 16\n",
    "embedding_size = 2 * node_embedding_size + 1  # 两个节点嵌入的大小加上一个额外的标签\n",
    "\n",
    "# 实例化MLP模型\n",
    "mlp = MLP(input_size=embedding_size)\n",
    "\n",
    "# 对每个图的嵌入进行预测并使用伯努利分布决定是否修改边\n",
    "mlp_predictions_per_graph = []\n",
    "mlp_decisions_per_graph = []\n",
    "\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    for graph_embeddings in combined_embeddings_per_graph:\n",
    "        graph_embeddings_tensor = torch.stack(graph_embeddings)\n",
    "        probabilities = mlp(graph_embeddings_tensor).squeeze()\n",
    "        bernoulli = torch.distributions.Bernoulli(probabilities)\n",
    "        decisions = bernoulli.sample()\n",
    "\n",
    "        mlp_predictions_per_graph.append(probabilities)\n",
    "        mlp_decisions_per_graph.append(decisions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改每张图的边\n",
    "modified_graphs = []\n",
    "\n",
    "for data, decisions, non_edges_samples in zip(dataset, mlp_decisions_per_graph, sample_non_edges(dataset)):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(data.num_nodes))\n",
    "\n",
    "    # 添加原始存在的边\n",
    "    for edge in data.edge_index.t().numpy():\n",
    "        G.add_edge(*edge)\n",
    "\n",
    "    # 遍历每个边和非边的决策\n",
    "    for i, decision in enumerate(decisions):\n",
    "        if decision.item() == 1:  # 如果MLP预测为1，修改边\n",
    "            if i < data.edge_index.size(1):  # 检查是边还是非边\n",
    "                # 确定边的方向\n",
    "                edge = data.edge_index[:, i].numpy()\n",
    "                edge = tuple(sorted(edge))\n",
    "                \n",
    "                # 删除原始存在的边（如果存在）\n",
    "                if G.has_edge(*edge):\n",
    "                    G.remove_edge(*edge)\n",
    "            else:\n",
    "                # 处理不存在的边\n",
    "                non_edge = non_edges_samples[i - data.edge_index.size(1)]\n",
    "                non_edge = tuple(sorted(non_edge))\n",
    "                \n",
    "                # 添加原本不存在的边\n",
    "                if not G.has_edge(*non_edge):\n",
    "                    G.add_edge(*non_edge)\n",
    "\n",
    "    modified_graphs.append(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將新的圖轉換成embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 modified_graphs 的图数据\n",
    "modified_dataset = []\n",
    "for G in modified_graphs:\n",
    "    # 从 NetworkX 图创建边索引\n",
    "    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "    \n",
    "    # 使用单位矩阵作为节点特征\n",
    "    x = torch.eye(G.number_of_nodes())\n",
    "    \n",
    "    # 创建 Data 对象\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    modified_dataset.append(data)\n",
    "\n",
    "# 使用 GAT 模型为 modified_graphs 生成嵌入\n",
    "model.eval()  # 确保模型处于评估模式\n",
    "modified_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for data in modified_dataset:\n",
    "        embedding = model(data)\n",
    "        modified_embeddings.append(embedding)\n",
    "\n",
    "# # 如果还没有为原始 dataset 生成嵌入，则重复该过程\n",
    "original_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for data in dataset:\n",
    "        embedding = model(data)\n",
    "        original_embeddings.append(embedding)\n",
    "\n",
    "# 现在，`modified_embeddings` 包含了修改后图的嵌入，`original_embeddings` 包含了原始图的嵌入\n",
    "\n",
    "# 获取两组嵌入的图级嵌入\n",
    "modified_graph_embeddings = get_graph_embedding(modified_embeddings)\n",
    "original_graph_embeddings = get_graph_embedding(original_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算余弦相似度，用來作為similarity loss\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "cosine_similarities = cos(modified_graph_embeddings, original_graph_embeddings)\n",
    "# cosine_similarities 包含每对图（修改后的图和原始图）之间的余弦相似度\n",
    "\n",
    "combined_embeddings = [torch.cat((mod_emb, orig_emb)) for mod_emb, orig_emb in zip(modified_graph_embeddings, original_graph_embeddings)]\n",
    "labels = []\n",
    "for mod_graph, orig_graph in zip(modified_graphs, dataset):\n",
    "    mod_mvc = len(calculate_MVC(to_networkx(mod_graph, to_undirected=True)))\n",
    "    orig_mvc = len(calculate_MVC(to_networkx(orig_graph, to_undirected=True)))\n",
    "    label = 1 if mod_mvc == orig_mvc else 0\n",
    "    labels.append(label)\n",
    "\n",
    "# 将嵌入和标签转换为张量\n",
    "combined_embeddings_tensor = torch.stack(combined_embeddings)\n",
    "labels_tensor = torch.tensor(labels)\n",
    "\n",
    "# 实例化 MLP 分类器，用來作為classification loss\n",
    "input_size = combined_embeddings_tensor.size(1)\n",
    "classifier = MLPClassifier(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代码继续\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# 训练模式\n",
    "classifier.train()\n",
    "\n",
    "# 假设一些训练超参数\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for combined_emb, label in zip(combined_embeddings_tensor, labels_tensor):\n",
    "        combined_emb = combined_emb.unsqueeze(0)  # 添加批次维度\n",
    "        label = label.unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "        # 正向传播\n",
    "        classifier_output = classifier(combined_emb)\n",
    "        classification_loss = criterion(classifier_output, label.float())\n",
    "\n",
    "        # 计算 similarity loss\n",
    "        modified_emb, original_emb = torch.split(combined_emb, split_size_or_sections=combined_emb.size(1)//2, dim=1)\n",
    "        similarity_loss = 1 - cos(modified_emb, original_emb).mean()\n",
    "\n",
    "        # 总损失\n",
    "        loss = classification_loss + similarity_loss\n",
    "        print(f\"loss = {loss:.4f}\")\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(combined_embeddings_tensor):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
