{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import random\n",
    "from heapdict import heapdict\n",
    "from node2vec import Node2Vec\n",
    "import argparse\n",
    "import torch.nn.init as init\n",
    "from utils import *\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义GCN模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,num_features, graph_embedding_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 128)\n",
    "        self.conv2 = GCNConv(128, graph_embedding_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定义GAT模型\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_heads=4, graph_embedding_size=256):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(num_features, 512, heads=num_heads, dropout=0.2)\n",
    "        self.gat2 = GATConv(512 * num_heads, graph_embedding_size, heads=1, concat=False, dropout=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 定義用來決定edge是否修改的MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc5.weight, nonlinearity='relu')\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pro = torch.softmax(self.fc4(x), dim=1)\n",
    "        binary_decision = torch.sigmoid(self.fc5(x))\n",
    "        return pro, binary_decision\n",
    "    \n",
    "class GCN_edge_modify(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels = 512):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # 最后一层，用于产生最终输出\n",
    "        self.out = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "class MLPClassifier(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 256)          # 第二层\n",
    "        self.fc3 = nn.Linear(256, 128)          # 第三层\n",
    "        self.fc4 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))        # 使用sigmoid确保输出在0到1之间\n",
    "        return x\n",
    "    \n",
    "class MVC_Predict(nn.Module):  #最後用來判定graph的result是否有相同的MVC\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # 第一层\n",
    "        self.fc2 = nn.Linear(512, 256)          # 第二层\n",
    "        self.fc3 = nn.Linear(256, 128)          # 第三层\n",
    "        self.fc4 = nn.Linear(128, 1)           # 输出层\n",
    "\n",
    "        init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.fc4.weight, nonlinearity='relu')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)       # 使用sigmoid确保输出在0到1之间\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modify_edge(nn.Module):\n",
    "    def __init__(self, num_features, graph_embedding_size, epoch = 100, lr = 0.0001, modified_edge = 30, GraphNumber = 50, Graphsize = 50, num_heads = 4):\n",
    "        super(Modify_edge, self).__init__()\n",
    "        self.connect_info_num = 5\n",
    "        self.gat = GAT(num_features=num_features + 1, num_heads=num_heads, graph_embedding_size = graph_embedding_size)  # 根据需要调整头数\n",
    "        self.mlp = MLP(input_size=3 * graph_embedding_size + self.connect_info_num)\n",
    "        self.classifier = MLPClassifier(input_size=2 * graph_embedding_size)\n",
    "        self.modified_edge = modified_edge\n",
    "        self.lr = lr\n",
    "        self.GraphNumber = GraphNumber\n",
    "        self.Graphsize = Graphsize\n",
    "        self.Node2Vec_feature = num_features\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.best_preserve = 0\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        self.modified_graphs = []\n",
    "        self.edge_dict = {}\n",
    "        self.whole_edge_set = set()\n",
    "        self.dataset = []\n",
    "        self.init_graph()  ## create self.dataset\n",
    "        \n",
    "        original_embeddings = []\n",
    "        for data in self.dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            original_embeddings.append(embedding)\n",
    "        self.original_graph_embeddings = self.get_graph_embedding(original_embeddings)\n",
    "        self.mlp_label = []\n",
    "        self.mlp_target = []\n",
    "        for emb, data, graph_emb in zip(original_embeddings, self.dataset, self.original_graph_embeddings):\n",
    "            modify_edge, edge_label, edge_softmax = self.generate_edge_embeddings(data, emb, graph_emb)\n",
    "            self.mlp_label.append(edge_label)\n",
    "            self.mlp_target.append(edge_softmax)\n",
    "            add_num = 0\n",
    "            delete_num = 0\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            for edge in modify_edge:  # decision: (probabilities,(u,v))\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    delete_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    add_num += 1\n",
    "            self.modified_graphs.append(G)\n",
    "            print(f\"add_num: {add_num}, delete_num: {delete_num}\")\n",
    "        self.modified_dataset = []  #type pyg\n",
    "        for G in self.modified_graphs:\n",
    "            # 从 NetworkX 图创建边索引\n",
    "            edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            # 使用单位矩阵作为节点特征\n",
    "            # x = torch.eye(G.number_of_nodes())\n",
    "            \n",
    "            # 创建 Data 对象\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.modified_dataset.append(data)  \n",
    "            \n",
    "        modified_embeddings = []\n",
    "        for data in self.modified_dataset:\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            modified_embeddings.append(embedding)  \n",
    "        self.modified_graph_embeddings = self.get_graph_embedding(modified_embeddings)\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        self.cosine_similarities = cos(self.modified_graph_embeddings, self.original_graph_embeddings).mean()\n",
    "            \n",
    "        labels = []\n",
    "        MVC_diff = 0\n",
    "        for mod_graph, orig_mvc in zip(self.modified_graphs, self.train_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(mod_graph))\n",
    "            # print(f\"mod_mvc: {mod_mvc}, ori_mvc: {orig_mvc}, diff: {abs(mod_mvc - orig_mvc)}\")\n",
    "            MVC_diff = MVC_diff + abs(mod_mvc - orig_mvc) * abs(mod_mvc - orig_mvc)\n",
    "            label = 1 if mod_mvc == orig_mvc else 0\n",
    "            labels.append(label)\n",
    "        print(f\"label presreved: {labels.count(1)}, MVC_diff : {MVC_diff}\")\n",
    "        label_preserve = labels.count(1)\n",
    "        if label_preserve > self.best_preserve:\n",
    "            self.best_preserve = label_preserve\n",
    "            torch.save(self.state_dict(), \"/workspace/Model/Modify_edge_model_1.pth\")\n",
    "        combined_embeddings = [torch.cat((mod_emb, orig_emb)) for mod_emb, orig_emb in zip(self.modified_graph_embeddings, self.original_graph_embeddings)]\n",
    "        # 将嵌入和标签转换为张量\n",
    "        combined_embeddings_tensor = torch.stack(combined_embeddings)\n",
    "        # combined_embeddings_tensor shape : torch.Size([50, 2*graph embedding]) 兩張graph的嵌入拼接起來\n",
    "        self.labels_tensor = torch.tensor(labels).to(self.device)\n",
    "        # labels_tensor shape : torch.Size([50]) 也就是50個graph的label\n",
    "        self.preserve_predict = self.classifier(combined_embeddings_tensor).squeeze()\n",
    "        # preserve_predict shape: torch.Size([50])也就是50個graph預測的label\n",
    "        \n",
    "        self.mlp_label = torch.stack(self.mlp_label, dim=0) # shape: torch.Size([50, 1225])\n",
    "        self.mlp_target = torch.stack(self.mlp_target, dim=0) # shape: torch.Size([50, 1225])\n",
    "\n",
    "        \n",
    "        return self.cosine_similarities, self.preserve_predict, self.labels_tensor, MVC_diff/self.GraphNumber, label_preserve, self.mlp_label, self.mlp_target\n",
    "        \n",
    "        \n",
    "    def init_graph(self):\n",
    "        \"\"\"construct or load training graph and use Node2vec to get node embedding\"\"\"\n",
    "        self.train_graphs, self.train_opt = pickle_load(\"/workspace/Synthetic_graph/Training_graph_50_withOPT.pkl\")\n",
    "        self.create_edge_dict(self.Graphsize)\n",
    "        for i in range(self.GraphNumber):\n",
    "            # p = random.uniform(graph_density[0], graph_density[1])\n",
    "            # G = nx.erdos_renyi_graph(graph_size, p)\n",
    "            G = self.train_graphs[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "            # x = torch.eye(G.number_of_nodes())  # 节点特征\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.dataset.append(data)\n",
    "            \n",
    "    def create_edge_dict(self,graph_size):\n",
    "        \"\"\"mapping edge to index\"\"\"\n",
    "        index = 0\n",
    "        for i in range(graph_size - 1):\n",
    "            for j in range(i + 1, graph_size):\n",
    "                self.whole_edge_set.add((i, j))\n",
    "                self.edge_dict[(i, j)] = index\n",
    "                index += 1\n",
    "        \n",
    "    def calculate_MVC(self,graph, UB=9999999, C=set()):\n",
    "        \"\"\"use branch and bound to find out the mvc result\"\"\"\n",
    "        if len(graph.edges()) == 0:\n",
    "            return C\n",
    "\n",
    "        v, _ = max(graph.degree(), key=lambda a: a[1])\n",
    "        # C1 分支：選擇鄰居\n",
    "        C1 = C.copy()\n",
    "        neighbors = set(graph.neighbors(v))\n",
    "        C1.update(neighbors)\n",
    "        graph_1 = graph.copy()\n",
    "        graph_1.remove_nodes_from(neighbors)\n",
    "        if len(C1) < UB:\n",
    "            C1 = self.calculate_MVC(graph_1, UB, C1)\n",
    "\n",
    "        # C2 分支：只選擇該節點\n",
    "        C2 = C.copy()\n",
    "        C2.add(v)\n",
    "        graph_2 = graph.copy()\n",
    "        graph_2.remove_node(v)\n",
    "        if len(C2) < UB:\n",
    "            C2 = self.calculate_MVC(graph_2, min(UB, len(C1)), C2)\n",
    "\n",
    "        return min(C1, C2, key=len)\n",
    "    \n",
    "    def predict_MVC (self,graph_emb):\n",
    "        \"\"\"predict the result of MVC\"\"\"\n",
    "        for emb in graph_emb:\n",
    "            result = self.MVC_predict(emb)\n",
    "            print(result)\n",
    "    \n",
    "    def get_graph_embedding(self,embeddings):\n",
    "        \"\"\"average all node embeddings to get graph embedding, embedding 是一個list，每個元素是一個graph的node embedding\"\"\"\n",
    "        graph_embeddings = []\n",
    "        for embedding in embeddings:\n",
    "            graph_embedding = embedding.mean(dim=0)  # 对所有节点嵌入求平均\n",
    "            graph_embeddings.append(graph_embedding)\n",
    "        return torch.stack(graph_embeddings)\n",
    "    \n",
    "    def generate_edge_embeddings(self,data, embedding, graph_emb):\n",
    "        \"\"\"generate and sample edge embeddings for training 需要修改\"\"\"\n",
    "        data= to_networkx(data, to_undirected=True)\n",
    "        edge_set = set(data.edges()) \n",
    "        edge_modify_label = [torch.tensor(0.0).to(self.device) for _ in range(len(self.whole_edge_set))]\n",
    "        edge_modify_softmax = []\n",
    "        edge_pro_list = []\n",
    "        none_edge_pro_list = []\n",
    "        gumbel_modify_edge = []  #紀錄那些邊被修改\n",
    "        for u,v in self.whole_edge_set:\n",
    "            node1_emb = embedding[u]\n",
    "            node2_emb = embedding[v]\n",
    "            if (u,v) in edge_set:\n",
    "                connect_info = torch.tensor([1.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb,connect_info , graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                if modify_pro == 1:\n",
    "                    gumbel_modify_edge.append((u,v))\n",
    "\n",
    "            else:\n",
    "                connect_info = torch.tensor([0.0]*self.connect_info_num).to(self.device)\n",
    "                node_pair_emb = torch.cat([node1_emb, node2_emb, connect_info, graph_emb])\n",
    "                node_pair_emb = node_pair_emb.unsqueeze(0)\n",
    "                probabilities, decision = self.mlp(node_pair_emb)\n",
    "                # print(f\"shape of probabilities: {probabilities.shape}, type: {type(probabilities)}, probabilities: {probabilities}, decision: {decision}, shape of decision: {decision.shape}\")\n",
    "                modify_pro = F.gumbel_softmax(probabilities, tau=1, hard=True)[0][1] #直接是0或1\n",
    "                none_edge_pro_list.append((decision,(u,v)))\n",
    "                edge_modify_softmax.append(modify_pro)\n",
    "                if modify_pro == 1:\n",
    "                    gumbel_modify_edge.append((u,v))\n",
    "        \n",
    "        \"\"\"計算label不需用gradient\"\"\"\n",
    "        edge_pro_list = sorted(edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        none_edge_pro_list = sorted(none_edge_pro_list, key=lambda x: x[0], reverse=True)\n",
    "        for i in range(len(edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0).to(self.device)\n",
    "        for i in range(len(none_edge_pro_list)):\n",
    "            if i < self.modified_edge:\n",
    "                index = self.edge_dict[none_edge_pro_list[i][1]]\n",
    "                edge_modify_label[index] = torch.tensor(1.0).to(self.device)\n",
    "        # print(f\"len of edge_modify_label : {len of edge_modify_softmax : {len(edge_modify_softmax)}, len(edge_modify_label)}, type of edge_modify_softmax[0] : {type(edge_modify_softmax[0])}, type of edge_modify_label[0] : {type(edge_modify_label[0])}\")\n",
    "        # print(f\"true in edge_modify_softmax : {edge_modify_softmax.count(torch.tensor(1.0))}, true in edge_modify_label : {edge_modify_label.count(torch.tensor(1.0))}, edge_modify_label : { edge_modify_label}\")\n",
    "        \n",
    "        combined_embeddings = gumbel_modify_edge\n",
    "        edge_modify_label = torch.stack(edge_modify_label, dim=0)\n",
    "        edge_modify_softmax = torch.stack(edge_modify_softmax, dim=0)\n",
    "        \n",
    "        return combined_embeddings, edge_modify_label, edge_modify_softmax\n",
    "    \n",
    "    def validation(self):\n",
    "        validation_data, valid_opt, pro = pickle_load(\"/workspace/Synthetic_graph/Validation_graph_200_withOPTPRO.pkl\")\n",
    "        valid_original_embeddings = []\n",
    "        self.valid_dataset = []\n",
    "        self.valid_modified_graphs = []\n",
    "        # 把validation data轉成pyg的data，並透過node2vec得到node feature，再輸入GAT得到node embedding，最後透過get_graph_embedding得到graph embedding\n",
    "        for i in range(len(validation_data)):\n",
    "            G = validation_data[i]\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64))\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64))\n",
    "            edge_index = torch.stack([row, col], dim=0)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            # embeddings = InitNodeEmb.wv # 50 node * 50 features\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            \n",
    "            # x = torch.tensor(embeddings.vectors, dtype=torch.float32)\n",
    "\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            self.valid_dataset.append(data)\n",
    "            data = data.to(self.device)\n",
    "            embedding = self.gat(data)\n",
    "            valid_original_embeddings.append(embedding)\n",
    "        self.valid_graph_embedding = self.get_graph_embedding(valid_original_embeddings)\n",
    "        \n",
    "        # 將每個graph的node embedding和graph embedding還有pyg data輸入generate_edge_embeddings得到要修改的edge，並直接修改成新的graph，用valid_modified_graphs儲存\n",
    "        for emb, data, graph_emb in zip(valid_original_embeddings, self.valid_dataset, self.valid_graph_embedding):\n",
    "            modify_edge, valid_edge_label, valid_edge_softmax = self.generate_edge_embeddings(data, emb, graph_emb) #pyg data是為了知道邊\n",
    "            G = to_networkx(data, to_undirected=True)\n",
    "            edge_modify_num = 0\n",
    "            for edge in modify_edge:\n",
    "                if (G.has_edge(edge[0], edge[1])):\n",
    "                    G.remove_edge(edge[0], edge[1])\n",
    "                    edge_modify_num += 1\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1])\n",
    "                    edge_modify_num += 1\n",
    "            self.valid_modified_graphs.append(G)\n",
    "        \n",
    "        valid_label_presever = 0\n",
    "        for val_mod_graph, ori_opt in zip(self.valid_modified_graphs, valid_opt):\n",
    "            mod_mvc = len(self.calculate_MVC(val_mod_graph))\n",
    "            if ori_opt == mod_mvc:\n",
    "                valid_label_presever += 1\n",
    "        print(f\"validation label presreved: {valid_label_presever}\")\n",
    "        \n",
    "    def return_graph_embedding(self,G_list):\n",
    "        \"\"\"average all node embeddings to get graph embedding\"\"\"\n",
    "        temp_list = []\n",
    "        for G in G_list:\n",
    "            adj_matrix = nx.adjacency_matrix(G)\n",
    "            adj_matrix = coo_matrix(adj_matrix)\n",
    "            row = torch.from_numpy(adj_matrix.row.astype(np.int64)).to(self.device)\n",
    "            col = torch.from_numpy(adj_matrix.col.astype(np.int64)).to(self.device)\n",
    "            edge_index = torch.stack([row, col], dim=0).to(self.device)\n",
    "            vec = Node2Vec(G, dimensions=self.Node2Vec_feature, walk_length=10, num_walks=10, workers=4, quiet=True)\n",
    "            InitNodeEmb = vec.fit(window=5, min_count=1, batch_words=4)\n",
    "            node2vec_embeddings = [InitNodeEmb.wv[str(i)] for i in range(len(G.nodes))]\n",
    "            node2vec_features_np = np.array(node2vec_embeddings)\n",
    "            degrees = nx.degree(G)\n",
    "            degree_values = [deg for node, deg in degrees]\n",
    "            degree_values = torch.tensor(degree_values, dtype=torch.float).to(self.device)\n",
    "            degree_normalized = (degree_values - degree_values.min()) / (degree_values.max() - degree_values.min())\n",
    "            degree_features = degree_normalized.view(-1, 1)\n",
    "            node2vec_features = torch.tensor(node2vec_features_np).to(self.device)\n",
    "            combined_features = torch.cat([degree_features, node2vec_features], dim=1)\n",
    "            data = Data(x=combined_features, edge_index=edge_index)\n",
    "            embedding = self.gat(data)\n",
    "            temp_list.append(embedding)\n",
    "        graph_embedding = self.get_graph_embedding(temp_list)\n",
    "        return graph_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel\n",
      "gat.gat1.att_src: requires_grad=True\n",
      "gat.gat1.att_dst: requires_grad=True\n",
      "gat.gat1.bias: requires_grad=True\n",
      "gat.gat1.lin_src.weight: requires_grad=True\n",
      "gat.gat2.att_src: requires_grad=True\n",
      "gat.gat2.att_dst: requires_grad=True\n",
      "gat.gat2.bias: requires_grad=True\n",
      "gat.gat2.lin_src.weight: requires_grad=True\n",
      "mlp.fc1.weight: requires_grad=True\n",
      "mlp.fc1.bias: requires_grad=True\n",
      "mlp.fc2.weight: requires_grad=True\n",
      "mlp.fc2.bias: requires_grad=True\n",
      "mlp.fc3.weight: requires_grad=True\n",
      "mlp.fc3.bias: requires_grad=True\n",
      "mlp.fc4.weight: requires_grad=True\n",
      "mlp.fc4.bias: requires_grad=True\n",
      "mlp.fc5.weight: requires_grad=True\n",
      "mlp.fc5.bias: requires_grad=True\n",
      "classifier.fc1.weight: requires_grad=True\n",
      "classifier.fc1.bias: requires_grad=True\n",
      "classifier.fc2.weight: requires_grad=True\n",
      "classifier.fc2.bias: requires_grad=True\n",
      "classifier.fc3.weight: requires_grad=True\n",
      "classifier.fc3.bias: requires_grad=True\n",
      "classifier.fc4.weight: requires_grad=True\n",
      "classifier.fc4.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "edge_sample_number = 100\n",
    "learning_rate = 0.0001\n",
    "mymodel = Modify_edge(num_features=128, graph_embedding_size=256, epoch=100, lr=learning_rate, modified_edge=edge_sample_number, GraphNumber=50, Graphsize=50, num_heads=4)\n",
    "mymodel.load_state_dict(torch.load(\"/workspace/Model/Modify_edge_test_stage.pth\"))\n",
    "mymodel = mymodel.to(device)\n",
    "print(\"mymodel\")\n",
    "for name, param in mymodel.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "BCEloss_fn = nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mymodel.parameters(), lr=learning_rate,weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_num: 101, delete_num: 229\n",
      "add_num: 127, delete_num: 205\n",
      "add_num: 118, delete_num: 205\n",
      "add_num: 155, delete_num: 191\n",
      "add_num: 242, delete_num: 90\n",
      "add_num: 86, delete_num: 241\n",
      "add_num: 175, delete_num: 143\n",
      "add_num: 200, delete_num: 113\n",
      "add_num: 182, delete_num: 146\n",
      "add_num: 226, delete_num: 127\n",
      "add_num: 127, delete_num: 218\n",
      "add_num: 115, delete_num: 241\n",
      "add_num: 198, delete_num: 118\n",
      "add_num: 120, delete_num: 221\n",
      "add_num: 194, delete_num: 150\n",
      "add_num: 131, delete_num: 196\n",
      "add_num: 114, delete_num: 213\n",
      "add_num: 219, delete_num: 128\n",
      "add_num: 176, delete_num: 126\n",
      "add_num: 100, delete_num: 210\n",
      "add_num: 219, delete_num: 104\n",
      "add_num: 107, delete_num: 216\n",
      "add_num: 144, delete_num: 199\n",
      "add_num: 220, delete_num: 118\n",
      "add_num: 224, delete_num: 122\n",
      "add_num: 226, delete_num: 106\n",
      "add_num: 83, delete_num: 242\n",
      "add_num: 89, delete_num: 216\n",
      "add_num: 197, delete_num: 104\n",
      "add_num: 138, delete_num: 211\n",
      "add_num: 154, delete_num: 141\n",
      "add_num: 128, delete_num: 186\n",
      "add_num: 210, delete_num: 93\n",
      "add_num: 222, delete_num: 111\n",
      "add_num: 107, delete_num: 230\n",
      "add_num: 206, delete_num: 115\n",
      "add_num: 116, delete_num: 201\n",
      "add_num: 210, delete_num: 123\n",
      "add_num: 191, delete_num: 132\n",
      "add_num: 207, delete_num: 136\n",
      "add_num: 150, delete_num: 169\n",
      "add_num: 140, delete_num: 186\n",
      "add_num: 154, delete_num: 162\n",
      "add_num: 156, delete_num: 178\n",
      "add_num: 156, delete_num: 176\n",
      "add_num: 155, delete_num: 151\n",
      "add_num: 255, delete_num: 92\n",
      "add_num: 227, delete_num: 129\n",
      "add_num: 198, delete_num: 120\n",
      "add_num: 187, delete_num: 132\n",
      "label presreved: 10, MVC_diff : 112\n",
      "Gradient of gat.gat1.att_src: 3.852619192912243e-05\n",
      "Gradient of gat.gat1.att_dst: 1.7800084606278688e-05\n",
      "Gradient of gat.gat1.bias: 0.006280933041125536\n",
      "Gradient of gat.gat1.lin_src.weight: 0.008559118956327438\n",
      "Gradient of gat.gat2.att_src: 5.548985063796863e-05\n",
      "Gradient of gat.gat2.att_dst: 4.96695024519711e-13\n",
      "Gradient of gat.gat2.bias: 0.0035735699348151684\n",
      "Gradient of gat.gat2.lin_src.weight: 0.008381704799830914\n",
      "Gradient of mlp.fc1.weight: None\n",
      "Gradient of mlp.fc1.bias: None\n",
      "Gradient of mlp.fc2.weight: None\n",
      "Gradient of mlp.fc2.bias: None\n",
      "Gradient of mlp.fc3.weight: None\n",
      "Gradient of mlp.fc3.bias: None\n",
      "Gradient of mlp.fc4.weight: None\n",
      "Gradient of mlp.fc4.bias: None\n",
      "Gradient of mlp.fc5.weight: None\n",
      "Gradient of mlp.fc5.bias: None\n",
      "Gradient of classifier.fc1.weight: None\n",
      "Gradient of classifier.fc1.bias: None\n",
      "Gradient of classifier.fc2.weight: None\n",
      "Gradient of classifier.fc2.bias: None\n",
      "Gradient of classifier.fc3.weight: None\n",
      "Gradient of classifier.fc3.bias: None\n",
      "Gradient of classifier.fc4.weight: None\n",
      "Gradient of classifier.fc4.bias: None\n",
      "Epoch: 0, Loss: 2.9146361351013184, similarity_weight: 1, similarity_loss: 0.9946361184120178, difference_loss: 2.24, none_label_preserve: 0.8, preserve_weight: 1, classifier_loss: 0.502540111541748, mlp_loss : 34.435916900634766, mlp_loss_weight: 0.3\n",
      "validation\n",
      "validation label presreved: 46\n",
      "add_num: 96, delete_num: 237\n",
      "add_num: 129, delete_num: 200\n",
      "add_num: 101, delete_num: 235\n",
      "add_num: 149, delete_num: 194\n",
      "add_num: 237, delete_num: 81\n",
      "add_num: 79, delete_num: 240\n",
      "add_num: 202, delete_num: 145\n",
      "add_num: 216, delete_num: 124\n",
      "add_num: 162, delete_num: 151\n",
      "add_num: 209, delete_num: 110\n",
      "add_num: 114, delete_num: 200\n",
      "add_num: 122, delete_num: 219\n",
      "add_num: 206, delete_num: 126\n",
      "add_num: 134, delete_num: 188\n",
      "add_num: 187, delete_num: 142\n",
      "add_num: 154, delete_num: 203\n",
      "add_num: 109, delete_num: 210\n",
      "add_num: 203, delete_num: 119\n",
      "add_num: 202, delete_num: 145\n",
      "add_num: 139, delete_num: 225\n",
      "add_num: 205, delete_num: 119\n",
      "add_num: 104, delete_num: 217\n",
      "add_num: 154, delete_num: 207\n",
      "add_num: 212, delete_num: 122\n",
      "add_num: 224, delete_num: 100\n",
      "add_num: 214, delete_num: 114\n",
      "add_num: 84, delete_num: 255\n",
      "add_num: 92, delete_num: 208\n",
      "add_num: 200, delete_num: 101\n",
      "add_num: 151, delete_num: 205\n",
      "add_num: 193, delete_num: 161\n",
      "add_num: 146, delete_num: 188\n",
      "add_num: 237, delete_num: 92\n",
      "add_num: 234, delete_num: 91\n",
      "add_num: 117, delete_num: 206\n",
      "add_num: 227, delete_num: 117\n",
      "add_num: 121, delete_num: 209\n",
      "add_num: 210, delete_num: 136\n",
      "add_num: 208, delete_num: 137\n",
      "add_num: 205, delete_num: 126\n",
      "add_num: 149, delete_num: 193\n",
      "add_num: 138, delete_num: 202\n",
      "add_num: 158, delete_num: 181\n",
      "add_num: 158, delete_num: 190\n",
      "add_num: 180, delete_num: 172\n",
      "add_num: 166, delete_num: 164\n",
      "add_num: 246, delete_num: 94\n",
      "add_num: 208, delete_num: 124\n",
      "add_num: 209, delete_num: 120\n",
      "add_num: 224, delete_num: 127\n",
      "label presreved: 9, MVC_diff : 98\n",
      "Gradient of gat.gat1.att_src: 7.663158612558618e-05\n",
      "Gradient of gat.gat1.att_dst: 2.0891895474051125e-05\n",
      "Gradient of gat.gat1.bias: 0.007084801327437162\n",
      "Gradient of gat.gat1.lin_src.weight: 0.009595460258424282\n",
      "Gradient of gat.gat2.att_src: 8.815574983600527e-05\n",
      "Gradient of gat.gat2.att_dst: 5.551777570653171e-13\n",
      "Gradient of gat.gat2.bias: 0.004092148970812559\n",
      "Gradient of gat.gat2.lin_src.weight: 0.00931476429104805\n",
      "Gradient of mlp.fc1.weight: None\n",
      "Gradient of mlp.fc1.bias: None\n",
      "Gradient of mlp.fc2.weight: None\n",
      "Gradient of mlp.fc2.bias: None\n",
      "Gradient of mlp.fc3.weight: None\n",
      "Gradient of mlp.fc3.bias: None\n",
      "Gradient of mlp.fc4.weight: None\n",
      "Gradient of mlp.fc4.bias: None\n",
      "Gradient of mlp.fc5.weight: None\n",
      "Gradient of mlp.fc5.bias: None\n",
      "Gradient of classifier.fc1.weight: None\n",
      "Gradient of classifier.fc1.bias: None\n",
      "Gradient of classifier.fc2.weight: None\n",
      "Gradient of classifier.fc2.bias: None\n",
      "Gradient of classifier.fc3.weight: None\n",
      "Gradient of classifier.fc3.bias: None\n",
      "Gradient of classifier.fc4.weight: None\n",
      "Gradient of classifier.fc4.bias: None\n",
      "Epoch: 1, Loss: 2.794167995452881, similarity_weight: 1, similarity_loss: 0.9941679835319519, difference_loss: 1.96, none_label_preserve: 0.82, preserve_weight: 1, classifier_loss: 0.4720405340194702, mlp_loss : 34.5926513671875, mlp_loss_weight: 0.3\n",
      "add_num: 91, delete_num: 222\n",
      "add_num: 113, delete_num: 202\n",
      "add_num: 100, delete_num: 232\n",
      "add_num: 146, delete_num: 213\n",
      "add_num: 234, delete_num: 89\n",
      "add_num: 76, delete_num: 239\n",
      "add_num: 182, delete_num: 137\n",
      "add_num: 232, delete_num: 119\n",
      "add_num: 167, delete_num: 152\n",
      "add_num: 193, delete_num: 111\n",
      "add_num: 133, delete_num: 187\n",
      "add_num: 109, delete_num: 224\n",
      "add_num: 197, delete_num: 148\n",
      "add_num: 147, delete_num: 196\n",
      "add_num: 185, delete_num: 161\n",
      "add_num: 146, delete_num: 183\n",
      "add_num: 119, delete_num: 204\n",
      "add_num: 220, delete_num: 124\n",
      "add_num: 198, delete_num: 146\n",
      "add_num: 118, delete_num: 199\n",
      "add_num: 189, delete_num: 119\n",
      "add_num: 103, delete_num: 227\n",
      "add_num: 159, delete_num: 205\n",
      "add_num: 228, delete_num: 117\n",
      "add_num: 234, delete_num: 117\n",
      "add_num: 217, delete_num: 104\n",
      "add_num: 87, delete_num: 230\n",
      "add_num: 106, delete_num: 226\n",
      "add_num: 235, delete_num: 105\n",
      "add_num: 137, delete_num: 185\n",
      "add_num: 165, delete_num: 158\n",
      "add_num: 129, delete_num: 192\n",
      "add_num: 217, delete_num: 96\n",
      "add_num: 228, delete_num: 86\n",
      "add_num: 97, delete_num: 183\n",
      "add_num: 175, delete_num: 112\n",
      "add_num: 113, delete_num: 204\n",
      "add_num: 197, delete_num: 137\n",
      "add_num: 208, delete_num: 139\n",
      "add_num: 195, delete_num: 130\n",
      "add_num: 156, delete_num: 194\n",
      "add_num: 135, delete_num: 174\n",
      "add_num: 139, delete_num: 146\n",
      "add_num: 134, delete_num: 171\n",
      "add_num: 164, delete_num: 172\n",
      "add_num: 164, delete_num: 168\n",
      "add_num: 258, delete_num: 101\n",
      "add_num: 202, delete_num: 127\n",
      "add_num: 201, delete_num: 120\n",
      "add_num: 199, delete_num: 131\n"
     ]
    }
   ],
   "source": [
    "diff_weight = 0.5 # MVC修改前後的差異\n",
    "similarity_weight = 1 # 修改前後的圖的相似度\n",
    "preserve_weight = 1 # 保留原本的label\n",
    "classification_weight = 1 # 用來判定graph的result是否有相同的MVC\n",
    "mlp_loss_weight = 0.3\n",
    "for epoch in range(30):\n",
    "    \n",
    "    mymodel.train()\n",
    "    similarity_loss , preserve_predict, labels_tensor, difference_loss, label_preserve, mlp_label, mlp_target = mymodel()\n",
    "        \n",
    "    mlp_loss = BCEloss_fn(mlp_target, mlp_label)   \n",
    "    \n",
    "    classifier_loss = criterion(preserve_predict, labels_tensor.float())\n",
    "    \n",
    "    none_preserve_loss = (mymodel.GraphNumber-label_preserve) /  mymodel.GraphNumber\n",
    "    \n",
    "    # loss = classifier_loss * classification_weight + similarity_loss * similarity_weight + none_preserve_loss * preserve_weight + mlp_loss * mlp_loss_weight + difference_loss * diff_weight\n",
    "    \n",
    "    loss = similarity_loss * similarity_weight + none_preserve_loss * preserve_weight + difference_loss * diff_weight\n",
    "    \n",
    "    # if epoch < 25:\n",
    "    #     mlp_loss_weight -= 0.01\n",
    "    \n",
    "    # if epoch < 30 :\n",
    "    #     similarity_weight += 0.01\n",
    "    #     preserve_weight += 0.02\n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for name, param in mymodel.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(f\"Gradient of {name}: {param.grad.norm()}\")\n",
    "        else:\n",
    "            print(f\"Gradient of {name}: None\")\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}, similarity_weight: {similarity_weight}, similarity_loss: {similarity_loss.item()}, difference_loss: {difference_loss}, none_label_preserve: {none_preserve_loss}, preserve_weight: {preserve_weight}, classifier_loss: {classifier_loss.item()}, mlp_loss : {mlp_loss.item()}, mlp_loss_weight: {mlp_loss_weight}\")\n",
    "    if epoch % 2 == 0:\n",
    "        print(\"validation\")\n",
    "        mymodel.eval()\n",
    "        with torch.no_grad():\n",
    "            mymodel.validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp loss 的用途是減少邊的修改\n",
    "similarity loss的用途是增加差異度\n",
    "classifier loss 是用來判定修改後的圖與修改前的圖是否MVC有改變\n",
    "difference loss 是用來表示50個training graph在這epoch的MVC差異\n",
    "None preserve loss 是計數器，看label preserve的數量"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
